{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aad5fc9",
   "metadata": {},
   "source": [
    "## Load The Data \"Tiny Stories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f282ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"./tinystories_local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c602d2",
   "metadata": {},
   "source": [
    "## GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34728301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set environment variable to reduce memory fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b8a28",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `PositionalEncoding` class adds positional information to token embeddings to capture the order of tokens in a sequence, as transformers lack inherent sequence awareness. It uses sinusoidal functions to generate encodings that allow the model to differentiate token positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24993a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35ddd9",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `MultiHeadSelfAttention` class implements multi-head self-attention, a core mechanism in transformers that allows the model to focus on different parts of the input sequence simultaneously across multiple attention heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Multi-Head Self-Attention\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.scale = math.sqrt(self.d_k)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        Q = self.W_q(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.W_o(context)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0127",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `FeedForward` class implements a position-wise feed-forward neural network (FFN) applied to each token in the sequence, adding non-linearity and increasing the model’s capacity to learn complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feed-Forward Neural Network\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030e579",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `DecoderLayer` class represents a single layer of the GPT-2 decoder, combining multi-head self-attention and a feed-forward network with residual connections and layer normalization for stable training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd88bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Transformer Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_output = self.self_attn(x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f03fc",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `GPT2` class defines the complete GPT-2 model architecture, stacking multiple decoder layers to process input tokens and generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. GPT-2 Model\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=768, num_layers=2, num_heads=12, d_ff=3072, max_len=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def generate(self, input_ids, max_length=50, method=\"greedy\"):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                mask = torch.tril(torch.ones(input_ids.size(1), input_ids.size(1), device=device)).unsqueeze(0).unsqueeze(0)\n",
    "                logits = self(input_ids, mask)[:, -1, :]\n",
    "                if method == \"greedy\":\n",
    "                    next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "                else:\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    next_token = torch.multinomial(probs, num_samples=1)\n",
    "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "                if next_token.item() == tokenizer.eos_token_id:\n",
    "                    break\n",
    "        return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460dd18",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `TinyStoriesDataset` class prepares the TinyStories dataset for training by tokenizing text samples and creating input-target pairs for language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87859a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Dataset Preparation\n",
    "class TinyStoriesDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=256):\n",
    "        self.data = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            text = self.data[idx][\"text\"]\n",
    "            encoding = self.tokenizer.encode(text, add_special_tokens=True, max_length=self.max_length, truncation=True)\n",
    "            encoding = encoding + [self.tokenizer.pad_token_id] * (self.max_length - len(encoding))\n",
    "            input_ids = torch.tensor(encoding[:-1], dtype=torch.long)\n",
    "            target_ids = torch.tensor(encoding[1:], dtype=torch.long)\n",
    "            return input_ids, target_ids\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {e}\")\n",
    "            encoding = [self.tokenizer.pad_token_id] * self.max_length\n",
    "            input_ids = torch.tensor(encoding[:-1], dtype=torch.long)\n",
    "            target_ids = torch.tensor(encoding[1:], dtype=torch.long)\n",
    "            return input_ids, target_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342aa0e5",
   "metadata": {},
   "source": [
    "**Explaination**:  \n",
    "This section initializes the tokenizer for the GPT-2 model using the `GPT2Tokenizer` from the `transformers` library.  \n",
    "- **Purpose**: Converts text into token IDs and vice versa, enabling the model to process input text and generate output.  \n",
    "- **Details**:  \n",
    "  - Loads the pre-trained GPT-2 tokenizer (`gpt2`) from Hugging Face.  \n",
    "  - Sets the padding token to the end-of-sequence (`eos`) token to ensure consistent handling of padded sequences.  \n",
    "- **Output**: A configured `tokenizer` object used for encoding/decoding text in the dataset and generation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load dataset locally and select the 'train' split\n",
    "dataset = load_from_disk(\"./tinystories_local\")\n",
    "train_dataset_full = dataset['train']\n",
    "\n",
    "# Select 10% of the dataset\n",
    "subset_size = int(0.1 * len(train_dataset_full))\n",
    "indices = [int(i) for i in np.random.choice(len(train_dataset_full), subset_size, replace=False)]\n",
    "subset_dataset = Subset(train_dataset_full, indices)\n",
    "\n",
    "# Split the subset into 90% train and 10% test\n",
    "train_size = int(0.9 * len(subset_dataset))\n",
    "test_size = len(subset_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(subset_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TinyStoriesDataset(train_dataset, tokenizer, max_length=256)\n",
    "test_data = TinyStoriesDataset(test_dataset, tokenizer, max_length=256)\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209bb5c",
   "metadata": {},
   "source": [
    "**Description**:  \n",
    "This section configures the GPT-2 model, optimizer, and loss function for training.  \n",
    "- **Purpose**: Sets up the model architecture and training components to process tokenized input and learn from the dataset.  \n",
    "- **Details**:  \n",
    "  - **Vocabulary Size**: Uses the tokenizer’s vocabulary size (`tokenizer.vocab_size`) to define the model’s output layer.  \n",
    "  - **Model**: Initializes a `GPT2` model with:  \n",
    "    - `d_model=768` (embedding dimension).  \n",
    "    - `num_layers=4` (transformer decoder layers).  \n",
    "    - `num_heads=12` (attention heads).  \n",
    "    - `d_ff=3072` (feed-forward dimension).  \n",
    "    - `max_len=256` (maximum sequence length).  \n",
    "    - Moves the model to the specified device (GPU or CPU).  \n",
    "  - **Optimizer**: Uses `AdamW` with a learning rate of `3e-4` for parameter optimization.  \n",
    "  - **Loss Function**: Uses `CrossEntropyLoss`, ignoring the padding token (`tokenizer.pad_token_id`) to avoid penalizing padding in the loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b512756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model Configuration\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = GPT2(vocab_size=vocab_size, d_model=768, num_layers=2, num_heads=12, d_ff=3072, max_len=256).to(device)\n",
    "# model = GPT2(vocab_size=vocab_size, d_model=512, num_layers=2, num_heads=8, d_ff=2048, max_len=256).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe1374",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `train_model` function trains the GPT-2 model using the provided data loader, loss function, and optimizer, incorporating gradient accumulation to manage memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710eb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Training Loop with Gradient Accumulation\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5, save_path=\"gpt2_model.pth\", accum_steps=2):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (input_ids, target_ids) in enumerate(train_loader):\n",
    "            input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "            mask = torch.tril(torch.ones(input_ids.size(1), input_ids.size(1), device=device)).unsqueeze(0).unsqueeze(0)\n",
    "            outputs = model(input_ids, mask)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), target_ids.view(-1))\n",
    "            loss = loss / accum_steps\n",
    "            loss.backward()\n",
    "\n",
    "            # Compute accuracy\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            mask = target_ids != tokenizer.pad_token_id\n",
    "            correct = (preds == target_ids).masked_select(mask).sum().item()\n",
    "            total_correct += correct\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "            if (batch_idx + 1) % accum_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item() * accum_steps\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{total_batches}, Loss: {loss.item() * accum_steps:.4f}\")\n",
    "\n",
    "        if (batch_idx + 1) % accum_steps != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_loss = total_loss / total_batches\n",
    "        avg_accuracy = total_correct / total_tokens if total_tokens > 0 else 0\n",
    "        epoch_losses.append(avg_loss)\n",
    "        epoch_accuracies.append(avg_accuracy)\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "        # Save model after each epoch\n",
    "        epoch_save_path = f\"gpt2_model_epoch_{epoch+1}.pth\"\n",
    "        torch.save(model.state_dict(), epoch_save_path)\n",
    "        print(f\"Model saved to {epoch_save_path}\")\n",
    "\n",
    "        # Generate text after each epoch\n",
    "        prompt = \"Once upon a time, in a small village\"\n",
    "        generated_text = generate_text(model, prompt, max_length=50, method=\"greedy\")\n",
    "        text_save_path = f\"generated_text_epoch_{epoch+1}.txt\"\n",
    "        with open(text_save_path, \"w\") as f:\n",
    "            f.write(generated_text)\n",
    "        print(f\"Generated text saved to {text_save_path}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Final model saved to {save_path}\")\n",
    "\n",
    "    # Plot loss and accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), epoch_losses, marker='o')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), epoch_accuracies, marker='o', color='orange')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png')\n",
    "    print(\"Training metrics plot saved to 'training_metrics.png'\")\n",
    "    # plt.show() is not used to avoid blocking\n",
    "\n",
    "    return epoch_losses, epoch_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0532d6",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `compute_perplexity` function evaluates the model’s performance on the test set by calculating perplexity, a metric that measures how well the model predicts the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Evaluation: Perplexity\n",
    "def compute_perplexity(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, target_ids in test_loader:\n",
    "            input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "            mask = torch.tril(torch.ones(input_ids.size(1), input_ids.size(1), device=device)).unsqueeze(0).unsqueeze(0)\n",
    "            outputs = model(input_ids, mask)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), target_ids.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7823e0",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `generate_text` function generates text from a given prompt using the trained GPT-2 model, either greedily or by sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Text Generation\n",
    "def generate_text(model, prompt, max_length=50, method=\"greedy\"):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(input_ids, max_length, method)\n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d70ab",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "**Purpose**: The `load_model` function loads a pre-trained model from a file for evaluation or text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927be9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Load Model for Testing\n",
    "def load_model(model, load_path=\"gpt2_model.pth\"):\n",
    "    model.load_state_dict(torch.load(load_path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {load_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0801073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1341: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 190773\n",
      "Batches per epoch: 23847\n",
      "Epoch 1, Batch 0/23847, Loss: 10.9593\n",
      "Epoch 1, Batch 100/23847, Loss: 5.1272\n",
      "Epoch 1, Batch 200/23847, Loss: 4.2372\n",
      "Epoch 1, Batch 300/23847, Loss: 4.1515\n",
      "Epoch 1, Batch 400/23847, Loss: 3.8328\n",
      "Epoch 1, Batch 500/23847, Loss: 3.9342\n",
      "Epoch 1, Batch 600/23847, Loss: 3.6265\n",
      "Epoch 1, Batch 700/23847, Loss: 3.6117\n",
      "Epoch 1, Batch 800/23847, Loss: 3.9043\n",
      "Epoch 1, Batch 900/23847, Loss: 3.5438\n",
      "Epoch 1, Batch 1000/23847, Loss: 3.6595\n",
      "Epoch 1, Batch 1100/23847, Loss: 3.8341\n",
      "Epoch 1, Batch 1200/23847, Loss: 3.2842\n",
      "Epoch 1, Batch 1300/23847, Loss: 3.8146\n",
      "Epoch 1, Batch 1400/23847, Loss: 3.4929\n",
      "Epoch 1, Batch 1500/23847, Loss: 3.2926\n",
      "Epoch 1, Batch 1600/23847, Loss: 3.5424\n",
      "Epoch 1, Batch 1700/23847, Loss: 3.6029\n",
      "Epoch 1, Batch 1800/23847, Loss: 3.1146\n",
      "Epoch 1, Batch 1900/23847, Loss: 3.5192\n",
      "Epoch 1, Batch 2000/23847, Loss: 3.3561\n",
      "Epoch 1, Batch 2100/23847, Loss: 3.4270\n",
      "Epoch 1, Batch 2200/23847, Loss: 3.5290\n",
      "Epoch 1, Batch 2300/23847, Loss: 3.2744\n",
      "Epoch 1, Batch 2400/23847, Loss: 3.0410\n",
      "Epoch 1, Batch 2500/23847, Loss: 3.2295\n",
      "Epoch 1, Batch 2600/23847, Loss: 3.3383\n",
      "Epoch 1, Batch 2700/23847, Loss: 3.1800\n",
      "Epoch 1, Batch 2800/23847, Loss: 3.4112\n",
      "Epoch 1, Batch 2900/23847, Loss: 3.1240\n",
      "Epoch 1, Batch 3000/23847, Loss: 3.2948\n",
      "Epoch 1, Batch 3100/23847, Loss: 3.4295\n",
      "Epoch 1, Batch 3200/23847, Loss: 3.2028\n",
      "Epoch 1, Batch 3300/23847, Loss: 3.2438\n",
      "Epoch 1, Batch 3400/23847, Loss: 3.1395\n",
      "Epoch 1, Batch 3500/23847, Loss: 2.9963\n",
      "Epoch 1, Batch 3600/23847, Loss: 3.3220\n",
      "Epoch 1, Batch 3700/23847, Loss: 3.1748\n",
      "Epoch 1, Batch 3800/23847, Loss: 3.0596\n",
      "Epoch 1, Batch 3900/23847, Loss: 3.2459\n",
      "Epoch 1, Batch 4000/23847, Loss: 3.1864\n",
      "Epoch 1, Batch 4100/23847, Loss: 3.1702\n",
      "Epoch 1, Batch 4200/23847, Loss: 3.1575\n",
      "Epoch 1, Batch 4300/23847, Loss: 2.9412\n",
      "Epoch 1, Batch 4400/23847, Loss: 3.3034\n",
      "Epoch 1, Batch 4500/23847, Loss: 3.1071\n",
      "Epoch 1, Batch 4600/23847, Loss: 3.1104\n",
      "Epoch 1, Batch 4700/23847, Loss: 2.9922\n",
      "Epoch 1, Batch 4800/23847, Loss: 2.9361\n",
      "Epoch 1, Batch 4900/23847, Loss: 2.8293\n",
      "Epoch 1, Batch 5000/23847, Loss: 3.0892\n",
      "Epoch 1, Batch 5100/23847, Loss: 3.0121\n",
      "Epoch 1, Batch 5200/23847, Loss: 3.3606\n",
      "Epoch 1, Batch 5300/23847, Loss: 3.0346\n",
      "Epoch 1, Batch 5400/23847, Loss: 2.8440\n",
      "Epoch 1, Batch 5500/23847, Loss: 3.2838\n",
      "Epoch 1, Batch 5600/23847, Loss: 2.8658\n",
      "Epoch 1, Batch 5700/23847, Loss: 2.8351\n",
      "Epoch 1, Batch 5800/23847, Loss: 3.0661\n",
      "Epoch 1, Batch 5900/23847, Loss: 2.9796\n",
      "Epoch 1, Batch 6000/23847, Loss: 2.7402\n",
      "Epoch 1, Batch 6100/23847, Loss: 3.2309\n",
      "Epoch 1, Batch 6200/23847, Loss: 2.9620\n",
      "Epoch 1, Batch 6300/23847, Loss: 3.1258\n",
      "Epoch 1, Batch 6400/23847, Loss: 3.0093\n",
      "Epoch 1, Batch 6500/23847, Loss: 3.0777\n",
      "Epoch 1, Batch 6600/23847, Loss: 2.9147\n",
      "Epoch 1, Batch 6700/23847, Loss: 2.9262\n",
      "Epoch 1, Batch 6800/23847, Loss: 3.0852\n",
      "Epoch 1, Batch 6900/23847, Loss: 2.9149\n",
      "Epoch 1, Batch 7000/23847, Loss: 3.0268\n",
      "Epoch 1, Batch 7100/23847, Loss: 2.7265\n",
      "Epoch 1, Batch 7200/23847, Loss: 2.9537\n",
      "Epoch 1, Batch 7300/23847, Loss: 2.8965\n",
      "Epoch 1, Batch 7400/23847, Loss: 2.8462\n",
      "Epoch 1, Batch 7500/23847, Loss: 2.6852\n",
      "Epoch 1, Batch 7600/23847, Loss: 2.9338\n",
      "Epoch 1, Batch 7700/23847, Loss: 2.8034\n",
      "Epoch 1, Batch 7800/23847, Loss: 3.0265\n",
      "Epoch 1, Batch 7900/23847, Loss: 2.8590\n",
      "Epoch 1, Batch 8000/23847, Loss: 2.9827\n",
      "Epoch 1, Batch 8100/23847, Loss: 2.8458\n",
      "Epoch 1, Batch 8200/23847, Loss: 3.0328\n",
      "Epoch 1, Batch 8300/23847, Loss: 2.9078\n",
      "Epoch 1, Batch 8400/23847, Loss: 3.0147\n",
      "Epoch 1, Batch 8500/23847, Loss: 3.0561\n",
      "Epoch 1, Batch 8600/23847, Loss: 2.5802\n",
      "Epoch 1, Batch 8700/23847, Loss: 3.0854\n",
      "Epoch 1, Batch 8800/23847, Loss: 2.7644\n",
      "Epoch 1, Batch 8900/23847, Loss: 2.5208\n",
      "Epoch 1, Batch 9000/23847, Loss: 2.9326\n",
      "Epoch 1, Batch 9100/23847, Loss: 3.0801\n",
      "Epoch 1, Batch 9200/23847, Loss: 2.4842\n",
      "Epoch 1, Batch 9300/23847, Loss: 2.7118\n",
      "Epoch 1, Batch 9400/23847, Loss: 2.6540\n",
      "Epoch 1, Batch 9500/23847, Loss: 3.0971\n",
      "Epoch 1, Batch 9600/23847, Loss: 2.5858\n",
      "Epoch 1, Batch 9700/23847, Loss: 2.8528\n",
      "Epoch 1, Batch 9800/23847, Loss: 2.9100\n",
      "Epoch 1, Batch 9900/23847, Loss: 2.6787\n",
      "Epoch 1, Batch 10000/23847, Loss: 2.8737\n",
      "Epoch 1, Batch 10100/23847, Loss: 2.4663\n",
      "Epoch 1, Batch 10200/23847, Loss: 2.8514\n",
      "Epoch 1, Batch 10300/23847, Loss: 2.7299\n",
      "Epoch 1, Batch 10400/23847, Loss: 2.6241\n",
      "Epoch 1, Batch 10500/23847, Loss: 2.8909\n",
      "Epoch 1, Batch 10600/23847, Loss: 3.0912\n",
      "Epoch 1, Batch 10700/23847, Loss: 2.9591\n",
      "Epoch 1, Batch 10800/23847, Loss: 2.5998\n",
      "Epoch 1, Batch 10900/23847, Loss: 2.5969\n",
      "Epoch 1, Batch 11000/23847, Loss: 2.9155\n",
      "Epoch 1, Batch 11100/23847, Loss: 2.8129\n",
      "Epoch 1, Batch 11200/23847, Loss: 2.5522\n",
      "Epoch 1, Batch 11300/23847, Loss: 2.8354\n",
      "Epoch 1, Batch 11400/23847, Loss: 3.0456\n",
      "Epoch 1, Batch 11500/23847, Loss: 2.6383\n",
      "Epoch 1, Batch 11600/23847, Loss: 2.5484\n",
      "Epoch 1, Batch 11700/23847, Loss: 2.6857\n",
      "Epoch 1, Batch 11800/23847, Loss: 2.8856\n",
      "Epoch 1, Batch 11900/23847, Loss: 2.9729\n",
      "Epoch 1, Batch 12000/23847, Loss: 2.7242\n",
      "Epoch 1, Batch 12100/23847, Loss: 2.8684\n",
      "Epoch 1, Batch 12200/23847, Loss: 2.4775\n",
      "Epoch 1, Batch 12300/23847, Loss: 2.6310\n",
      "Epoch 1, Batch 12400/23847, Loss: 2.5906\n",
      "Epoch 1, Batch 12500/23847, Loss: 2.7111\n",
      "Epoch 1, Batch 12600/23847, Loss: 2.6380\n",
      "Epoch 1, Batch 12700/23847, Loss: 2.5885\n",
      "Epoch 1, Batch 12800/23847, Loss: 2.8111\n",
      "Epoch 1, Batch 12900/23847, Loss: 2.7125\n",
      "Epoch 1, Batch 13000/23847, Loss: 2.7781\n",
      "Epoch 1, Batch 13100/23847, Loss: 2.8081\n",
      "Epoch 1, Batch 13200/23847, Loss: 2.7701\n",
      "Epoch 1, Batch 13300/23847, Loss: 2.6285\n",
      "Epoch 1, Batch 13400/23847, Loss: 2.6060\n",
      "Epoch 1, Batch 13500/23847, Loss: 2.7803\n",
      "Epoch 1, Batch 13600/23847, Loss: 2.5410\n",
      "Epoch 1, Batch 13700/23847, Loss: 2.4872\n",
      "Epoch 1, Batch 13800/23847, Loss: 2.9108\n",
      "Epoch 1, Batch 13900/23847, Loss: 2.7002\n",
      "Epoch 1, Batch 14000/23847, Loss: 2.6441\n",
      "Epoch 1, Batch 14100/23847, Loss: 2.4859\n",
      "Epoch 1, Batch 14200/23847, Loss: 2.7503\n",
      "Epoch 1, Batch 14300/23847, Loss: 2.6173\n",
      "Epoch 1, Batch 14400/23847, Loss: 2.7558\n",
      "Epoch 1, Batch 14500/23847, Loss: 2.5816\n",
      "Epoch 1, Batch 14600/23847, Loss: 2.4928\n",
      "Epoch 1, Batch 14700/23847, Loss: 2.8648\n",
      "Epoch 1, Batch 14800/23847, Loss: 2.4234\n",
      "Epoch 1, Batch 14900/23847, Loss: 2.7082\n",
      "Epoch 1, Batch 15000/23847, Loss: 2.9133\n",
      "Epoch 1, Batch 15100/23847, Loss: 2.5422\n",
      "Epoch 1, Batch 15200/23847, Loss: 2.7948\n",
      "Epoch 1, Batch 15300/23847, Loss: 2.6569\n",
      "Epoch 1, Batch 15400/23847, Loss: 2.5492\n",
      "Epoch 1, Batch 15500/23847, Loss: 2.6033\n",
      "Epoch 1, Batch 15600/23847, Loss: 2.5554\n",
      "Epoch 1, Batch 15700/23847, Loss: 2.6520\n",
      "Epoch 1, Batch 15800/23847, Loss: 2.6742\n",
      "Epoch 1, Batch 15900/23847, Loss: 2.7835\n",
      "Epoch 1, Batch 16000/23847, Loss: 2.5800\n",
      "Epoch 1, Batch 16100/23847, Loss: 2.6618\n",
      "Epoch 1, Batch 16200/23847, Loss: 2.7088\n",
      "Epoch 1, Batch 16300/23847, Loss: 2.7315\n",
      "Epoch 1, Batch 16400/23847, Loss: 3.0847\n",
      "Epoch 1, Batch 16500/23847, Loss: 2.6160\n",
      "Epoch 1, Batch 16600/23847, Loss: 2.6142\n",
      "Epoch 1, Batch 16700/23847, Loss: 2.7850\n",
      "Epoch 1, Batch 16800/23847, Loss: 2.7351\n",
      "Epoch 1, Batch 16900/23847, Loss: 2.9949\n",
      "Epoch 1, Batch 17000/23847, Loss: 2.7453\n",
      "Epoch 1, Batch 17100/23847, Loss: 2.5827\n",
      "Epoch 1, Batch 17200/23847, Loss: 2.6490\n",
      "Epoch 1, Batch 17300/23847, Loss: 2.5180\n",
      "Epoch 1, Batch 17400/23847, Loss: 2.6673\n",
      "Epoch 1, Batch 17500/23847, Loss: 2.5055\n",
      "Epoch 1, Batch 17600/23847, Loss: 2.5256\n",
      "Epoch 1, Batch 17700/23847, Loss: 2.7268\n",
      "Epoch 1, Batch 17800/23847, Loss: 2.8005\n",
      "Epoch 1, Batch 17900/23847, Loss: 2.6232\n",
      "Epoch 1, Batch 18000/23847, Loss: 2.4306\n",
      "Epoch 1, Batch 18100/23847, Loss: 2.6291\n",
      "Epoch 1, Batch 18200/23847, Loss: 2.4310\n",
      "Epoch 1, Batch 18300/23847, Loss: 2.8308\n",
      "Epoch 1, Batch 18400/23847, Loss: 2.8668\n",
      "Epoch 1, Batch 18500/23847, Loss: 2.5542\n",
      "Epoch 1, Batch 18600/23847, Loss: 2.7277\n",
      "Epoch 1, Batch 18700/23847, Loss: 2.5269\n",
      "Epoch 1, Batch 18800/23847, Loss: 2.3625\n",
      "Epoch 1, Batch 18900/23847, Loss: 2.5474\n",
      "Epoch 1, Batch 19000/23847, Loss: 2.2456\n",
      "Epoch 1, Batch 19100/23847, Loss: 2.6884\n",
      "Epoch 1, Batch 19200/23847, Loss: 2.5324\n",
      "Epoch 1, Batch 19300/23847, Loss: 2.4323\n",
      "Epoch 1, Batch 19400/23847, Loss: 2.6887\n",
      "Epoch 1, Batch 19500/23847, Loss: 2.6242\n",
      "Epoch 1, Batch 19600/23847, Loss: 2.5938\n",
      "Epoch 1, Batch 19700/23847, Loss: 2.6482\n",
      "Epoch 1, Batch 19800/23847, Loss: 2.6292\n",
      "Epoch 1, Batch 19900/23847, Loss: 2.5540\n",
      "Epoch 1, Batch 20000/23847, Loss: 2.4387\n",
      "Epoch 1, Batch 20100/23847, Loss: 2.5549\n",
      "Epoch 1, Batch 20200/23847, Loss: 2.4604\n",
      "Epoch 1, Batch 20300/23847, Loss: 2.7421\n",
      "Epoch 1, Batch 20400/23847, Loss: 2.5370\n",
      "Epoch 1, Batch 20500/23847, Loss: 2.3656\n",
      "Epoch 1, Batch 20600/23847, Loss: 2.5947\n",
      "Epoch 1, Batch 20700/23847, Loss: 2.4969\n",
      "Epoch 1, Batch 20800/23847, Loss: 2.4649\n",
      "Epoch 1, Batch 20900/23847, Loss: 2.5264\n",
      "Epoch 1, Batch 21000/23847, Loss: 2.7763\n",
      "Epoch 1, Batch 21100/23847, Loss: 2.3276\n",
      "Epoch 1, Batch 21200/23847, Loss: 2.4914\n",
      "Epoch 1, Batch 21300/23847, Loss: 2.7732\n",
      "Epoch 1, Batch 21400/23847, Loss: 2.6060\n",
      "Epoch 1, Batch 21500/23847, Loss: 2.3547\n",
      "Epoch 1, Batch 21600/23847, Loss: 2.5563\n",
      "Epoch 1, Batch 21700/23847, Loss: 2.9762\n",
      "Epoch 1, Batch 21800/23847, Loss: 2.5004\n",
      "Epoch 1, Batch 21900/23847, Loss: 2.3989\n",
      "Epoch 1, Batch 22000/23847, Loss: 2.5972\n",
      "Epoch 1, Batch 22100/23847, Loss: 2.5253\n",
      "Epoch 1, Batch 22200/23847, Loss: 2.5897\n",
      "Epoch 1, Batch 22300/23847, Loss: 2.4762\n",
      "Epoch 1, Batch 22400/23847, Loss: 2.4724\n",
      "Epoch 1, Batch 22500/23847, Loss: 2.3883\n",
      "Epoch 1, Batch 22600/23847, Loss: 2.6905\n",
      "Epoch 1, Batch 22700/23847, Loss: 2.6790\n",
      "Epoch 1, Batch 22800/23847, Loss: 2.3693\n",
      "Epoch 1, Batch 22900/23847, Loss: 2.6063\n",
      "Epoch 1, Batch 23000/23847, Loss: 2.4881\n",
      "Epoch 1, Batch 23100/23847, Loss: 2.4988\n",
      "Epoch 1, Batch 23200/23847, Loss: 2.5463\n",
      "Epoch 1, Batch 23300/23847, Loss: 2.6351\n",
      "Epoch 1, Batch 23400/23847, Loss: 2.6287\n",
      "Epoch 1, Batch 23500/23847, Loss: 2.6353\n",
      "Epoch 1, Batch 23600/23847, Loss: 2.3488\n",
      "Epoch 1, Batch 23700/23847, Loss: 2.6619\n",
      "Epoch 1, Batch 23800/23847, Loss: 2.2592\n",
      "Epoch 1, Average Loss: 2.8644, Average Accuracy: 0.3850\n",
      "Model saved to gpt2_model_epoch_1.pth\n",
      "Generated text saved to generated_text_epoch_1.txt\n",
      "Epoch 2, Batch 0/23847, Loss: 2.4860\n",
      "Epoch 2, Batch 100/23847, Loss: 2.6389\n",
      "Epoch 2, Batch 200/23847, Loss: 2.2907\n",
      "Epoch 2, Batch 300/23847, Loss: 2.5966\n",
      "Epoch 2, Batch 400/23847, Loss: 2.3969\n",
      "Epoch 2, Batch 500/23847, Loss: 2.4237\n",
      "Epoch 2, Batch 600/23847, Loss: 2.4579\n",
      "Epoch 2, Batch 700/23847, Loss: 2.3984\n",
      "Epoch 2, Batch 800/23847, Loss: 2.4419\n",
      "Epoch 2, Batch 900/23847, Loss: 2.4651\n",
      "Epoch 2, Batch 1000/23847, Loss: 2.3214\n",
      "Epoch 2, Batch 1100/23847, Loss: 2.3948\n",
      "Epoch 2, Batch 1200/23847, Loss: 2.2472\n",
      "Epoch 2, Batch 1300/23847, Loss: 2.5682\n",
      "Epoch 2, Batch 1400/23847, Loss: 2.4119\n",
      "Epoch 2, Batch 1500/23847, Loss: 2.6438\n",
      "Epoch 2, Batch 1600/23847, Loss: 2.3870\n",
      "Epoch 2, Batch 1700/23847, Loss: 2.8916\n",
      "Epoch 2, Batch 1800/23847, Loss: 2.6046\n",
      "Epoch 2, Batch 1900/23847, Loss: 2.6789\n",
      "Epoch 2, Batch 2000/23847, Loss: 2.3490\n",
      "Epoch 2, Batch 2100/23847, Loss: 2.2198\n",
      "Epoch 2, Batch 2200/23847, Loss: 2.2838\n",
      "Epoch 2, Batch 2300/23847, Loss: 2.5300\n",
      "Epoch 2, Batch 2400/23847, Loss: 2.3201\n",
      "Epoch 2, Batch 2500/23847, Loss: 2.4911\n",
      "Epoch 2, Batch 2600/23847, Loss: 2.3790\n",
      "Epoch 2, Batch 2700/23847, Loss: 2.3960\n",
      "Epoch 2, Batch 2800/23847, Loss: 2.5064\n",
      "Epoch 2, Batch 2900/23847, Loss: 2.4168\n",
      "Epoch 2, Batch 3000/23847, Loss: 2.4028\n",
      "Epoch 2, Batch 3100/23847, Loss: 2.2273\n",
      "Epoch 2, Batch 3200/23847, Loss: 2.4903\n",
      "Epoch 2, Batch 3300/23847, Loss: 2.4408\n",
      "Epoch 2, Batch 3400/23847, Loss: 2.3255\n",
      "Epoch 2, Batch 3500/23847, Loss: 2.5763\n",
      "Epoch 2, Batch 3600/23847, Loss: 2.4613\n",
      "Epoch 2, Batch 3700/23847, Loss: 2.5353\n",
      "Epoch 2, Batch 3800/23847, Loss: 2.3358\n",
      "Epoch 2, Batch 3900/23847, Loss: 2.4005\n",
      "Epoch 2, Batch 4000/23847, Loss: 2.3015\n",
      "Epoch 2, Batch 4100/23847, Loss: 2.5283\n",
      "Epoch 2, Batch 4200/23847, Loss: 2.3711\n",
      "Epoch 2, Batch 4300/23847, Loss: 2.4149\n",
      "Epoch 2, Batch 4400/23847, Loss: 2.4691\n",
      "Epoch 2, Batch 4500/23847, Loss: 2.3294\n",
      "Epoch 2, Batch 4600/23847, Loss: 2.2746\n",
      "Epoch 2, Batch 4700/23847, Loss: 2.4171\n",
      "Epoch 2, Batch 4800/23847, Loss: 2.0422\n",
      "Epoch 2, Batch 4900/23847, Loss: 2.3050\n",
      "Epoch 2, Batch 5000/23847, Loss: 2.3811\n",
      "Epoch 2, Batch 5100/23847, Loss: 2.2309\n",
      "Epoch 2, Batch 5200/23847, Loss: 2.4375\n",
      "Epoch 2, Batch 5300/23847, Loss: 2.5130\n",
      "Epoch 2, Batch 5400/23847, Loss: 2.2359\n",
      "Epoch 2, Batch 5500/23847, Loss: 2.5601\n",
      "Epoch 2, Batch 5600/23847, Loss: 2.3181\n",
      "Epoch 2, Batch 5700/23847, Loss: 2.1753\n",
      "Epoch 2, Batch 5800/23847, Loss: 2.5025\n",
      "Epoch 2, Batch 5900/23847, Loss: 2.2647\n",
      "Epoch 2, Batch 6000/23847, Loss: 2.1547\n",
      "Epoch 2, Batch 6100/23847, Loss: 2.2915\n",
      "Epoch 2, Batch 6200/23847, Loss: 2.3473\n",
      "Epoch 2, Batch 6300/23847, Loss: 2.3490\n",
      "Epoch 2, Batch 6400/23847, Loss: 2.1734\n",
      "Epoch 2, Batch 6500/23847, Loss: 2.4433\n",
      "Epoch 2, Batch 6600/23847, Loss: 2.4881\n",
      "Epoch 2, Batch 6700/23847, Loss: 2.3253\n",
      "Epoch 2, Batch 6800/23847, Loss: 2.3876\n",
      "Epoch 2, Batch 6900/23847, Loss: 2.0588\n",
      "Epoch 2, Batch 7000/23847, Loss: 2.2365\n",
      "Epoch 2, Batch 7100/23847, Loss: 2.3367\n",
      "Epoch 2, Batch 7200/23847, Loss: 2.4754\n",
      "Epoch 2, Batch 7300/23847, Loss: 2.3027\n",
      "Epoch 2, Batch 7400/23847, Loss: 2.4892\n",
      "Epoch 2, Batch 7500/23847, Loss: 2.4963\n",
      "Epoch 2, Batch 7600/23847, Loss: 2.2501\n",
      "Epoch 2, Batch 7700/23847, Loss: 2.6291\n",
      "Epoch 2, Batch 7800/23847, Loss: 2.3880\n",
      "Epoch 2, Batch 7900/23847, Loss: 2.4198\n",
      "Epoch 2, Batch 8000/23847, Loss: 2.3410\n",
      "Epoch 2, Batch 8100/23847, Loss: 2.2783\n",
      "Epoch 2, Batch 8200/23847, Loss: 2.3449\n",
      "Epoch 2, Batch 8300/23847, Loss: 2.0763\n",
      "Epoch 2, Batch 8400/23847, Loss: 2.5259\n",
      "Epoch 2, Batch 8500/23847, Loss: 2.2679\n",
      "Epoch 2, Batch 8600/23847, Loss: 2.2378\n",
      "Epoch 2, Batch 8700/23847, Loss: 2.4530\n",
      "Epoch 2, Batch 8800/23847, Loss: 2.4496\n",
      "Epoch 2, Batch 8900/23847, Loss: 2.2815\n",
      "Epoch 2, Batch 9000/23847, Loss: 2.2828\n",
      "Epoch 2, Batch 9100/23847, Loss: 2.6827\n",
      "Epoch 2, Batch 9200/23847, Loss: 2.2147\n",
      "Epoch 2, Batch 9300/23847, Loss: 2.0636\n",
      "Epoch 2, Batch 9400/23847, Loss: 2.5393\n",
      "Epoch 2, Batch 9500/23847, Loss: 2.5415\n",
      "Epoch 2, Batch 9600/23847, Loss: 2.2889\n",
      "Epoch 2, Batch 9700/23847, Loss: 2.2672\n",
      "Epoch 2, Batch 9800/23847, Loss: 2.2615\n",
      "Epoch 2, Batch 9900/23847, Loss: 2.0195\n",
      "Epoch 2, Batch 10000/23847, Loss: 2.1703\n",
      "Epoch 2, Batch 10100/23847, Loss: 2.3199\n",
      "Epoch 2, Batch 10200/23847, Loss: 2.1737\n",
      "Epoch 2, Batch 10300/23847, Loss: 2.2844\n",
      "Epoch 2, Batch 10400/23847, Loss: 2.1969\n",
      "Epoch 2, Batch 10500/23847, Loss: 2.3941\n",
      "Epoch 2, Batch 10600/23847, Loss: 2.3989\n",
      "Epoch 2, Batch 10700/23847, Loss: 2.1948\n",
      "Epoch 2, Batch 10800/23847, Loss: 2.1828\n",
      "Epoch 2, Batch 10900/23847, Loss: 2.3695\n",
      "Epoch 2, Batch 11000/23847, Loss: 2.2457\n",
      "Epoch 2, Batch 11100/23847, Loss: 2.4810\n",
      "Epoch 2, Batch 11200/23847, Loss: 2.3102\n",
      "Epoch 2, Batch 11300/23847, Loss: 2.3434\n",
      "Epoch 2, Batch 11400/23847, Loss: 2.3678\n",
      "Epoch 2, Batch 11500/23847, Loss: 2.2831\n",
      "Epoch 2, Batch 11600/23847, Loss: 2.3869\n",
      "Epoch 2, Batch 11700/23847, Loss: 2.4414\n",
      "Epoch 2, Batch 11800/23847, Loss: 2.2983\n",
      "Epoch 2, Batch 11900/23847, Loss: 2.2385\n",
      "Epoch 2, Batch 12000/23847, Loss: 2.1291\n",
      "Epoch 2, Batch 12100/23847, Loss: 2.2419\n",
      "Epoch 2, Batch 12200/23847, Loss: 2.3646\n",
      "Epoch 2, Batch 12300/23847, Loss: 2.2806\n",
      "Epoch 2, Batch 12400/23847, Loss: 2.2857\n",
      "Epoch 2, Batch 12500/23847, Loss: 2.1111\n",
      "Epoch 2, Batch 12600/23847, Loss: 2.2986\n",
      "Epoch 2, Batch 12700/23847, Loss: 2.3179\n",
      "Epoch 2, Batch 12800/23847, Loss: 2.3643\n",
      "Epoch 2, Batch 12900/23847, Loss: 2.3165\n",
      "Epoch 2, Batch 13000/23847, Loss: 2.3114\n",
      "Epoch 2, Batch 13100/23847, Loss: 2.1086\n",
      "Epoch 2, Batch 13200/23847, Loss: 2.1859\n",
      "Epoch 2, Batch 13300/23847, Loss: 2.1393\n",
      "Epoch 2, Batch 13400/23847, Loss: 2.0368\n",
      "Epoch 2, Batch 13500/23847, Loss: 2.1201\n",
      "Epoch 2, Batch 13600/23847, Loss: 2.5462\n",
      "Epoch 2, Batch 13700/23847, Loss: 2.1095\n",
      "Epoch 2, Batch 13800/23847, Loss: 2.2374\n",
      "Epoch 2, Batch 13900/23847, Loss: 2.2925\n",
      "Epoch 2, Batch 14000/23847, Loss: 2.6142\n",
      "Epoch 2, Batch 14100/23847, Loss: 2.5571\n",
      "Epoch 2, Batch 14200/23847, Loss: 2.0900\n",
      "Epoch 2, Batch 14300/23847, Loss: 2.3713\n",
      "Epoch 2, Batch 14400/23847, Loss: 2.2743\n",
      "Epoch 2, Batch 14500/23847, Loss: 2.2856\n",
      "Epoch 2, Batch 14600/23847, Loss: 2.1199\n",
      "Epoch 2, Batch 14700/23847, Loss: 2.3141\n",
      "Epoch 2, Batch 14800/23847, Loss: 2.4164\n",
      "Epoch 2, Batch 14900/23847, Loss: 2.3292\n",
      "Epoch 2, Batch 15000/23847, Loss: 1.8211\n",
      "Epoch 2, Batch 15100/23847, Loss: 2.1296\n",
      "Epoch 2, Batch 15200/23847, Loss: 1.9128\n",
      "Epoch 2, Batch 15300/23847, Loss: 2.2059\n",
      "Epoch 2, Batch 15400/23847, Loss: 2.2825\n",
      "Epoch 2, Batch 15500/23847, Loss: 2.4777\n",
      "Epoch 2, Batch 15600/23847, Loss: 2.2123\n",
      "Epoch 2, Batch 15700/23847, Loss: 2.3554\n",
      "Epoch 2, Batch 15800/23847, Loss: 2.0517\n",
      "Epoch 2, Batch 15900/23847, Loss: 2.0250\n",
      "Epoch 2, Batch 16000/23847, Loss: 2.3263\n",
      "Epoch 2, Batch 16100/23847, Loss: 2.2814\n",
      "Epoch 2, Batch 16200/23847, Loss: 2.3169\n",
      "Epoch 2, Batch 16300/23847, Loss: 2.2497\n",
      "Epoch 2, Batch 16400/23847, Loss: 2.1748\n",
      "Epoch 2, Batch 16500/23847, Loss: 2.4119\n",
      "Epoch 2, Batch 16600/23847, Loss: 2.2430\n",
      "Epoch 2, Batch 16700/23847, Loss: 2.5061\n",
      "Epoch 2, Batch 16800/23847, Loss: 2.2455\n",
      "Epoch 2, Batch 16900/23847, Loss: 2.3571\n",
      "Epoch 2, Batch 17000/23847, Loss: 1.9407\n",
      "Epoch 2, Batch 17100/23847, Loss: 2.4555\n",
      "Epoch 2, Batch 17200/23847, Loss: 2.3206\n",
      "Epoch 2, Batch 17300/23847, Loss: 2.1592\n",
      "Epoch 2, Batch 17400/23847, Loss: 2.3122\n",
      "Epoch 2, Batch 17500/23847, Loss: 2.2534\n",
      "Epoch 2, Batch 17600/23847, Loss: 2.2206\n",
      "Epoch 2, Batch 17700/23847, Loss: 2.2469\n",
      "Epoch 2, Batch 17800/23847, Loss: 2.3695\n",
      "Epoch 2, Batch 17900/23847, Loss: 2.3303\n",
      "Epoch 2, Batch 18000/23847, Loss: 2.1813\n",
      "Epoch 2, Batch 18100/23847, Loss: 2.3126\n",
      "Epoch 2, Batch 18200/23847, Loss: 2.1883\n",
      "Epoch 2, Batch 18300/23847, Loss: 2.3073\n",
      "Epoch 2, Batch 18400/23847, Loss: 2.1330\n",
      "Epoch 2, Batch 18500/23847, Loss: 2.2054\n",
      "Epoch 2, Batch 18600/23847, Loss: 2.1904\n",
      "Epoch 2, Batch 18700/23847, Loss: 2.1745\n",
      "Epoch 2, Batch 18800/23847, Loss: 2.1941\n",
      "Epoch 2, Batch 18900/23847, Loss: 2.4254\n",
      "Epoch 2, Batch 19000/23847, Loss: 2.3407\n",
      "Epoch 2, Batch 19100/23847, Loss: 1.9340\n",
      "Epoch 2, Batch 19200/23847, Loss: 2.1114\n",
      "Epoch 2, Batch 19300/23847, Loss: 2.3392\n",
      "Epoch 2, Batch 19400/23847, Loss: 2.3187\n",
      "Epoch 2, Batch 19500/23847, Loss: 2.0216\n",
      "Epoch 2, Batch 19600/23847, Loss: 2.1339\n",
      "Epoch 2, Batch 19700/23847, Loss: 2.3792\n",
      "Epoch 2, Batch 19800/23847, Loss: 1.9402\n",
      "Epoch 2, Batch 19900/23847, Loss: 2.0321\n",
      "Epoch 2, Batch 20000/23847, Loss: 2.1794\n",
      "Epoch 2, Batch 20100/23847, Loss: 2.3523\n",
      "Epoch 2, Batch 20200/23847, Loss: 2.1723\n",
      "Epoch 2, Batch 20300/23847, Loss: 2.6595\n",
      "Epoch 2, Batch 20400/23847, Loss: 2.1943\n",
      "Epoch 2, Batch 20500/23847, Loss: 2.2098\n",
      "Epoch 2, Batch 20600/23847, Loss: 2.0655\n",
      "Epoch 2, Batch 20700/23847, Loss: 2.3095\n",
      "Epoch 2, Batch 20800/23847, Loss: 2.2063\n",
      "Epoch 2, Batch 20900/23847, Loss: 2.3589\n",
      "Epoch 2, Batch 21000/23847, Loss: 2.2734\n",
      "Epoch 2, Batch 21100/23847, Loss: 1.9570\n",
      "Epoch 2, Batch 21200/23847, Loss: 2.2087\n",
      "Epoch 2, Batch 21300/23847, Loss: 2.3295\n",
      "Epoch 2, Batch 21400/23847, Loss: 2.1254\n",
      "Epoch 2, Batch 21500/23847, Loss: 2.3209\n",
      "Epoch 2, Batch 21600/23847, Loss: 1.9995\n",
      "Epoch 2, Batch 21700/23847, Loss: 2.0966\n",
      "Epoch 2, Batch 21800/23847, Loss: 2.3432\n",
      "Epoch 2, Batch 21900/23847, Loss: 2.1855\n",
      "Epoch 2, Batch 22000/23847, Loss: 2.2285\n",
      "Epoch 2, Batch 22100/23847, Loss: 2.0469\n",
      "Epoch 2, Batch 22200/23847, Loss: 2.0386\n",
      "Epoch 2, Batch 22300/23847, Loss: 2.2444\n",
      "Epoch 2, Batch 22400/23847, Loss: 2.2451\n",
      "Epoch 2, Batch 22500/23847, Loss: 2.1112\n",
      "Epoch 2, Batch 22600/23847, Loss: 2.2028\n",
      "Epoch 2, Batch 22700/23847, Loss: 2.2292\n",
      "Epoch 2, Batch 22800/23847, Loss: 2.2423\n",
      "Epoch 2, Batch 22900/23847, Loss: 2.2161\n",
      "Epoch 2, Batch 23000/23847, Loss: 2.3567\n",
      "Epoch 2, Batch 23100/23847, Loss: 2.2334\n",
      "Epoch 2, Batch 23200/23847, Loss: 2.4414\n",
      "Epoch 2, Batch 23300/23847, Loss: 2.0391\n",
      "Epoch 2, Batch 23400/23847, Loss: 2.3107\n",
      "Epoch 2, Batch 23500/23847, Loss: 2.3356\n",
      "Epoch 2, Batch 23600/23847, Loss: 2.2788\n",
      "Epoch 2, Batch 23700/23847, Loss: 2.3215\n",
      "Epoch 2, Batch 23800/23847, Loss: 1.9938\n",
      "Epoch 2, Average Loss: 2.2940, Average Accuracy: 0.4625\n",
      "Model saved to gpt2_model_epoch_2.pth\n",
      "Generated text saved to generated_text_epoch_2.txt\n",
      "Epoch 3, Batch 0/23847, Loss: 2.0637\n",
      "Epoch 3, Batch 100/23847, Loss: 1.8332\n",
      "Epoch 3, Batch 200/23847, Loss: 2.4475\n",
      "Epoch 3, Batch 300/23847, Loss: 2.2479\n",
      "Epoch 3, Batch 400/23847, Loss: 2.0014\n",
      "Epoch 3, Batch 500/23847, Loss: 2.4270\n",
      "Epoch 3, Batch 600/23847, Loss: 2.1559\n",
      "Epoch 3, Batch 700/23847, Loss: 2.2281\n",
      "Epoch 3, Batch 800/23847, Loss: 2.1807\n",
      "Epoch 3, Batch 900/23847, Loss: 2.1794\n",
      "Epoch 3, Batch 1000/23847, Loss: 2.3912\n",
      "Epoch 3, Batch 1100/23847, Loss: 2.1987\n",
      "Epoch 3, Batch 1200/23847, Loss: 2.3410\n",
      "Epoch 3, Batch 1300/23847, Loss: 2.3078\n",
      "Epoch 3, Batch 1400/23847, Loss: 1.9419\n",
      "Epoch 3, Batch 1500/23847, Loss: 2.0353\n",
      "Epoch 3, Batch 1600/23847, Loss: 2.1559\n",
      "Epoch 3, Batch 1700/23847, Loss: 2.4284\n",
      "Epoch 3, Batch 1800/23847, Loss: 1.8575\n",
      "Epoch 3, Batch 1900/23847, Loss: 2.0413\n",
      "Epoch 3, Batch 2000/23847, Loss: 1.9580\n",
      "Epoch 3, Batch 2100/23847, Loss: 2.1577\n",
      "Epoch 3, Batch 2200/23847, Loss: 1.9892\n",
      "Epoch 3, Batch 2300/23847, Loss: 2.3046\n",
      "Epoch 3, Batch 2400/23847, Loss: 2.2252\n",
      "Epoch 3, Batch 2500/23847, Loss: 2.1545\n",
      "Epoch 3, Batch 2600/23847, Loss: 2.2437\n",
      "Epoch 3, Batch 2700/23847, Loss: 2.0708\n",
      "Epoch 3, Batch 2800/23847, Loss: 2.2691\n",
      "Epoch 3, Batch 2900/23847, Loss: 1.9009\n",
      "Epoch 3, Batch 3000/23847, Loss: 1.9140\n",
      "Epoch 3, Batch 3100/23847, Loss: 1.9178\n",
      "Epoch 3, Batch 3200/23847, Loss: 2.2499\n",
      "Epoch 3, Batch 3300/23847, Loss: 2.0255\n",
      "Epoch 3, Batch 3400/23847, Loss: 2.3660\n",
      "Epoch 3, Batch 3500/23847, Loss: 2.3074\n",
      "Epoch 3, Batch 3600/23847, Loss: 2.2234\n",
      "Epoch 3, Batch 3700/23847, Loss: 1.9587\n",
      "Epoch 3, Batch 3800/23847, Loss: 2.2964\n",
      "Epoch 3, Batch 3900/23847, Loss: 2.2057\n",
      "Epoch 3, Batch 4000/23847, Loss: 2.1401\n",
      "Epoch 3, Batch 4100/23847, Loss: 1.9642\n",
      "Epoch 3, Batch 4200/23847, Loss: 2.2164\n",
      "Epoch 3, Batch 4300/23847, Loss: 1.9705\n",
      "Epoch 3, Batch 4400/23847, Loss: 1.9085\n",
      "Epoch 3, Batch 4500/23847, Loss: 2.0552\n",
      "Epoch 3, Batch 4600/23847, Loss: 2.1038\n",
      "Epoch 3, Batch 4700/23847, Loss: 1.9357\n",
      "Epoch 3, Batch 4800/23847, Loss: 2.0428\n",
      "Epoch 3, Batch 4900/23847, Loss: 2.2707\n",
      "Epoch 3, Batch 5000/23847, Loss: 2.0845\n",
      "Epoch 3, Batch 5100/23847, Loss: 2.0955\n",
      "Epoch 3, Batch 5200/23847, Loss: 2.1771\n",
      "Epoch 3, Batch 5300/23847, Loss: 2.0042\n",
      "Epoch 3, Batch 5400/23847, Loss: 1.9580\n",
      "Epoch 3, Batch 5500/23847, Loss: 2.0946\n",
      "Epoch 3, Batch 5600/23847, Loss: 2.2892\n",
      "Epoch 3, Batch 5700/23847, Loss: 2.2648\n",
      "Epoch 3, Batch 5800/23847, Loss: 1.9661\n",
      "Epoch 3, Batch 5900/23847, Loss: 2.2278\n",
      "Epoch 3, Batch 6000/23847, Loss: 2.0248\n",
      "Epoch 3, Batch 6100/23847, Loss: 2.2477\n",
      "Epoch 3, Batch 6200/23847, Loss: 1.9020\n",
      "Epoch 3, Batch 6300/23847, Loss: 2.2699\n",
      "Epoch 3, Batch 6400/23847, Loss: 1.9101\n",
      "Epoch 3, Batch 6500/23847, Loss: 2.0771\n",
      "Epoch 3, Batch 6600/23847, Loss: 2.0292\n",
      "Epoch 3, Batch 6700/23847, Loss: 1.6379\n",
      "Epoch 3, Batch 6800/23847, Loss: 2.2003\n",
      "Epoch 3, Batch 6900/23847, Loss: 2.0375\n",
      "Epoch 3, Batch 7000/23847, Loss: 2.3010\n",
      "Epoch 3, Batch 7100/23847, Loss: 2.0570\n",
      "Epoch 3, Batch 7200/23847, Loss: 1.9635\n",
      "Epoch 3, Batch 7300/23847, Loss: 2.0150\n",
      "Epoch 3, Batch 7400/23847, Loss: 1.8371\n",
      "Epoch 3, Batch 7500/23847, Loss: 2.0789\n",
      "Epoch 3, Batch 7600/23847, Loss: 2.3773\n",
      "Epoch 3, Batch 7700/23847, Loss: 2.3046\n",
      "Epoch 3, Batch 7800/23847, Loss: 2.1367\n",
      "Epoch 3, Batch 7900/23847, Loss: 2.2124\n",
      "Epoch 3, Batch 8000/23847, Loss: 2.1422\n",
      "Epoch 3, Batch 8100/23847, Loss: 1.8738\n",
      "Epoch 3, Batch 8200/23847, Loss: 2.0067\n",
      "Epoch 3, Batch 8300/23847, Loss: 2.2048\n",
      "Epoch 3, Batch 8400/23847, Loss: 1.9239\n",
      "Epoch 3, Batch 8500/23847, Loss: 1.9718\n",
      "Epoch 3, Batch 8600/23847, Loss: 1.9611\n",
      "Epoch 3, Batch 8700/23847, Loss: 1.7931\n",
      "Epoch 3, Batch 8800/23847, Loss: 2.2594\n",
      "Epoch 3, Batch 8900/23847, Loss: 2.0250\n",
      "Epoch 3, Batch 9000/23847, Loss: 1.9862\n",
      "Epoch 3, Batch 9100/23847, Loss: 2.1606\n",
      "Epoch 3, Batch 9200/23847, Loss: 1.9956\n",
      "Epoch 3, Batch 9300/23847, Loss: 2.2555\n",
      "Epoch 3, Batch 9400/23847, Loss: 1.8482\n",
      "Epoch 3, Batch 9500/23847, Loss: 2.2514\n",
      "Epoch 3, Batch 9600/23847, Loss: 2.1820\n",
      "Epoch 3, Batch 9700/23847, Loss: 2.4138\n",
      "Epoch 3, Batch 9800/23847, Loss: 2.1636\n",
      "Epoch 3, Batch 9900/23847, Loss: 2.0284\n",
      "Epoch 3, Batch 10000/23847, Loss: 1.9543\n",
      "Epoch 3, Batch 10100/23847, Loss: 2.1890\n",
      "Epoch 3, Batch 10200/23847, Loss: 2.1691\n",
      "Epoch 3, Batch 10300/23847, Loss: 2.0963\n",
      "Epoch 3, Batch 10400/23847, Loss: 2.0501\n",
      "Epoch 3, Batch 10500/23847, Loss: 2.3830\n",
      "Epoch 3, Batch 10600/23847, Loss: 2.1487\n",
      "Epoch 3, Batch 10700/23847, Loss: 2.1015\n",
      "Epoch 3, Batch 10800/23847, Loss: 2.1931\n",
      "Epoch 3, Batch 10900/23847, Loss: 1.8963\n",
      "Epoch 3, Batch 11000/23847, Loss: 2.0503\n",
      "Epoch 3, Batch 11100/23847, Loss: 2.1249\n",
      "Epoch 3, Batch 11200/23847, Loss: 2.0683\n",
      "Epoch 3, Batch 11300/23847, Loss: 2.0079\n",
      "Epoch 3, Batch 11400/23847, Loss: 2.1343\n",
      "Epoch 3, Batch 11500/23847, Loss: 2.0080\n",
      "Epoch 3, Batch 11600/23847, Loss: 1.9243\n",
      "Epoch 3, Batch 11700/23847, Loss: 2.2720\n",
      "Epoch 3, Batch 11800/23847, Loss: 1.9816\n",
      "Epoch 3, Batch 11900/23847, Loss: 2.1537\n",
      "Epoch 3, Batch 12000/23847, Loss: 2.2349\n",
      "Epoch 3, Batch 12100/23847, Loss: 2.0646\n",
      "Epoch 3, Batch 12200/23847, Loss: 1.8484\n",
      "Epoch 3, Batch 12300/23847, Loss: 2.1520\n",
      "Epoch 3, Batch 12400/23847, Loss: 2.1511\n",
      "Epoch 3, Batch 12500/23847, Loss: 2.0010\n",
      "Epoch 3, Batch 12600/23847, Loss: 2.2523\n",
      "Epoch 3, Batch 12700/23847, Loss: 1.8463\n",
      "Epoch 3, Batch 12800/23847, Loss: 1.9057\n",
      "Epoch 3, Batch 12900/23847, Loss: 2.2265\n",
      "Epoch 3, Batch 13000/23847, Loss: 2.0525\n",
      "Epoch 3, Batch 13100/23847, Loss: 2.0731\n",
      "Epoch 3, Batch 13200/23847, Loss: 2.0924\n",
      "Epoch 3, Batch 13300/23847, Loss: 1.9594\n",
      "Epoch 3, Batch 13400/23847, Loss: 2.2063\n",
      "Epoch 3, Batch 13500/23847, Loss: 2.1013\n",
      "Epoch 3, Batch 13600/23847, Loss: 2.3518\n",
      "Epoch 3, Batch 13700/23847, Loss: 2.2156\n",
      "Epoch 3, Batch 13800/23847, Loss: 1.8190\n",
      "Epoch 3, Batch 13900/23847, Loss: 2.0614\n",
      "Epoch 3, Batch 14000/23847, Loss: 1.7024\n",
      "Epoch 3, Batch 14100/23847, Loss: 2.1897\n",
      "Epoch 3, Batch 14200/23847, Loss: 1.7958\n",
      "Epoch 3, Batch 14300/23847, Loss: 1.9182\n",
      "Epoch 3, Batch 14400/23847, Loss: 2.0449\n",
      "Epoch 3, Batch 14500/23847, Loss: 2.3421\n",
      "Epoch 3, Batch 14600/23847, Loss: 1.6940\n",
      "Epoch 3, Batch 14700/23847, Loss: 2.1791\n",
      "Epoch 3, Batch 14800/23847, Loss: 2.4430\n",
      "Epoch 3, Batch 14900/23847, Loss: 1.8368\n",
      "Epoch 3, Batch 15000/23847, Loss: 1.9855\n",
      "Epoch 3, Batch 15100/23847, Loss: 1.8524\n",
      "Epoch 3, Batch 15200/23847, Loss: 2.1373\n",
      "Epoch 3, Batch 15300/23847, Loss: 1.9347\n",
      "Epoch 3, Batch 15400/23847, Loss: 1.9168\n",
      "Epoch 3, Batch 15500/23847, Loss: 2.0666\n",
      "Epoch 3, Batch 15600/23847, Loss: 2.0542\n",
      "Epoch 3, Batch 15700/23847, Loss: 2.1438\n",
      "Epoch 3, Batch 15800/23847, Loss: 2.1091\n",
      "Epoch 3, Batch 15900/23847, Loss: 2.1968\n",
      "Epoch 3, Batch 16000/23847, Loss: 2.1233\n",
      "Epoch 3, Batch 16100/23847, Loss: 2.0125\n",
      "Epoch 3, Batch 16200/23847, Loss: 1.9241\n",
      "Epoch 3, Batch 16300/23847, Loss: 1.8266\n",
      "Epoch 3, Batch 16400/23847, Loss: 1.9997\n",
      "Epoch 3, Batch 16500/23847, Loss: 2.0330\n",
      "Epoch 3, Batch 16600/23847, Loss: 2.0069\n",
      "Epoch 3, Batch 16700/23847, Loss: 1.8647\n",
      "Epoch 3, Batch 16800/23847, Loss: 2.0287\n",
      "Epoch 3, Batch 16900/23847, Loss: 2.2601\n",
      "Epoch 3, Batch 17000/23847, Loss: 2.0409\n",
      "Epoch 3, Batch 17100/23847, Loss: 1.9730\n",
      "Epoch 3, Batch 17200/23847, Loss: 1.7990\n",
      "Epoch 3, Batch 17300/23847, Loss: 2.3206\n",
      "Epoch 3, Batch 17400/23847, Loss: 1.9117\n",
      "Epoch 3, Batch 17500/23847, Loss: 2.0809\n",
      "Epoch 3, Batch 17600/23847, Loss: 1.9317\n",
      "Epoch 3, Batch 17700/23847, Loss: 2.1649\n",
      "Epoch 3, Batch 17800/23847, Loss: 2.0768\n",
      "Epoch 3, Batch 17900/23847, Loss: 1.9700\n",
      "Epoch 3, Batch 18000/23847, Loss: 2.2014\n",
      "Epoch 3, Batch 18100/23847, Loss: 2.2647\n",
      "Epoch 3, Batch 18200/23847, Loss: 2.1525\n",
      "Epoch 3, Batch 18300/23847, Loss: 1.8742\n",
      "Epoch 3, Batch 18400/23847, Loss: 1.9424\n",
      "Epoch 3, Batch 18500/23847, Loss: 2.2030\n",
      "Epoch 3, Batch 18600/23847, Loss: 1.9738\n",
      "Epoch 3, Batch 18700/23847, Loss: 2.2610\n",
      "Epoch 3, Batch 18800/23847, Loss: 1.9957\n",
      "Epoch 3, Batch 18900/23847, Loss: 2.2416\n",
      "Epoch 3, Batch 19000/23847, Loss: 2.0743\n",
      "Epoch 3, Batch 19100/23847, Loss: 2.1124\n",
      "Epoch 3, Batch 19200/23847, Loss: 2.0485\n",
      "Epoch 3, Batch 19300/23847, Loss: 2.1340\n",
      "Epoch 3, Batch 19400/23847, Loss: 2.1915\n",
      "Epoch 3, Batch 19500/23847, Loss: 2.0141\n",
      "Epoch 3, Batch 19600/23847, Loss: 2.0487\n",
      "Epoch 3, Batch 19700/23847, Loss: 1.9231\n",
      "Epoch 3, Batch 19800/23847, Loss: 1.9793\n",
      "Epoch 3, Batch 19900/23847, Loss: 1.8788\n",
      "Epoch 3, Batch 20000/23847, Loss: 2.1571\n",
      "Epoch 3, Batch 20100/23847, Loss: 2.2605\n",
      "Epoch 3, Batch 20200/23847, Loss: 2.1451\n",
      "Epoch 3, Batch 20300/23847, Loss: 2.0621\n",
      "Epoch 3, Batch 20400/23847, Loss: 1.9955\n",
      "Epoch 3, Batch 20500/23847, Loss: 2.1540\n",
      "Epoch 3, Batch 20600/23847, Loss: 2.1453\n",
      "Epoch 3, Batch 20700/23847, Loss: 1.8791\n",
      "Epoch 3, Batch 20800/23847, Loss: 2.0810\n",
      "Epoch 3, Batch 20900/23847, Loss: 2.0602\n",
      "Epoch 3, Batch 21000/23847, Loss: 2.0400\n",
      "Epoch 3, Batch 21100/23847, Loss: 1.8348\n",
      "Epoch 3, Batch 21200/23847, Loss: 2.0969\n",
      "Epoch 3, Batch 21300/23847, Loss: 2.0647\n",
      "Epoch 3, Batch 21400/23847, Loss: 1.9294\n",
      "Epoch 3, Batch 21500/23847, Loss: 1.9188\n",
      "Epoch 3, Batch 21600/23847, Loss: 2.2095\n",
      "Epoch 3, Batch 21700/23847, Loss: 1.7935\n",
      "Epoch 3, Batch 21800/23847, Loss: 2.2399\n",
      "Epoch 3, Batch 21900/23847, Loss: 2.2242\n",
      "Epoch 3, Batch 22000/23847, Loss: 2.0561\n",
      "Epoch 3, Batch 22100/23847, Loss: 2.2579\n",
      "Epoch 3, Batch 22200/23847, Loss: 2.0162\n",
      "Epoch 3, Batch 22300/23847, Loss: 2.0059\n",
      "Epoch 3, Batch 22400/23847, Loss: 2.1769\n",
      "Epoch 3, Batch 22500/23847, Loss: 1.7526\n",
      "Epoch 3, Batch 22600/23847, Loss: 2.1960\n",
      "Epoch 3, Batch 22700/23847, Loss: 2.1422\n",
      "Epoch 3, Batch 22800/23847, Loss: 2.1924\n",
      "Epoch 3, Batch 22900/23847, Loss: 2.0782\n",
      "Epoch 3, Batch 23000/23847, Loss: 2.1581\n",
      "Epoch 3, Batch 23100/23847, Loss: 2.3417\n",
      "Epoch 3, Batch 23200/23847, Loss: 1.9913\n",
      "Epoch 3, Batch 23300/23847, Loss: 2.2529\n",
      "Epoch 3, Batch 23400/23847, Loss: 1.7544\n",
      "Epoch 3, Batch 23500/23847, Loss: 2.0362\n",
      "Epoch 3, Batch 23600/23847, Loss: 2.0786\n",
      "Epoch 3, Batch 23700/23847, Loss: 2.0278\n",
      "Epoch 3, Batch 23800/23847, Loss: 1.9755\n",
      "Epoch 3, Average Loss: 2.0984, Average Accuracy: 0.4952\n",
      "Model saved to gpt2_model_epoch_3.pth\n",
      "Generated text saved to generated_text_epoch_3.txt\n",
      "Epoch 4, Batch 0/23847, Loss: 1.9697\n",
      "Epoch 4, Batch 100/23847, Loss: 1.7983\n",
      "Epoch 4, Batch 200/23847, Loss: 2.0919\n",
      "Epoch 4, Batch 300/23847, Loss: 1.9221\n",
      "Epoch 4, Batch 400/23847, Loss: 2.2494\n",
      "Epoch 4, Batch 500/23847, Loss: 1.9070\n",
      "Epoch 4, Batch 600/23847, Loss: 2.0410\n",
      "Epoch 4, Batch 700/23847, Loss: 1.7492\n",
      "Epoch 4, Batch 800/23847, Loss: 2.0828\n",
      "Epoch 4, Batch 900/23847, Loss: 2.0580\n",
      "Epoch 4, Batch 1000/23847, Loss: 2.0323\n",
      "Epoch 4, Batch 1100/23847, Loss: 2.2082\n",
      "Epoch 4, Batch 1200/23847, Loss: 1.8477\n",
      "Epoch 4, Batch 1300/23847, Loss: 1.9945\n",
      "Epoch 4, Batch 1400/23847, Loss: 1.9115\n",
      "Epoch 4, Batch 1500/23847, Loss: 1.7192\n",
      "Epoch 4, Batch 1600/23847, Loss: 1.9951\n",
      "Epoch 4, Batch 1700/23847, Loss: 2.0047\n",
      "Epoch 4, Batch 1800/23847, Loss: 1.9355\n",
      "Epoch 4, Batch 1900/23847, Loss: 1.9439\n",
      "Epoch 4, Batch 2000/23847, Loss: 2.2127\n",
      "Epoch 4, Batch 2100/23847, Loss: 2.1033\n",
      "Epoch 4, Batch 2200/23847, Loss: 1.9885\n",
      "Epoch 4, Batch 2300/23847, Loss: 1.9240\n",
      "Epoch 4, Batch 2400/23847, Loss: 1.9777\n",
      "Epoch 4, Batch 2500/23847, Loss: 2.0758\n",
      "Epoch 4, Batch 2600/23847, Loss: 1.8625\n",
      "Epoch 4, Batch 2700/23847, Loss: 2.2319\n",
      "Epoch 4, Batch 2800/23847, Loss: 1.8232\n",
      "Epoch 4, Batch 2900/23847, Loss: 1.8521\n",
      "Epoch 4, Batch 3000/23847, Loss: 2.1143\n",
      "Epoch 4, Batch 3100/23847, Loss: 2.0937\n",
      "Epoch 4, Batch 3200/23847, Loss: 1.8852\n",
      "Epoch 4, Batch 3300/23847, Loss: 2.0302\n",
      "Epoch 4, Batch 3400/23847, Loss: 1.9988\n",
      "Epoch 4, Batch 3500/23847, Loss: 1.9578\n",
      "Epoch 4, Batch 3600/23847, Loss: 1.9136\n",
      "Epoch 4, Batch 3700/23847, Loss: 1.8968\n",
      "Epoch 4, Batch 3800/23847, Loss: 1.8395\n",
      "Epoch 4, Batch 3900/23847, Loss: 1.9548\n",
      "Epoch 4, Batch 4000/23847, Loss: 2.2558\n",
      "Epoch 4, Batch 4100/23847, Loss: 1.8706\n",
      "Epoch 4, Batch 4200/23847, Loss: 2.3144\n",
      "Epoch 4, Batch 4300/23847, Loss: 1.9884\n",
      "Epoch 4, Batch 4400/23847, Loss: 2.0559\n",
      "Epoch 4, Batch 4500/23847, Loss: 2.0287\n",
      "Epoch 4, Batch 4600/23847, Loss: 2.1168\n",
      "Epoch 4, Batch 4700/23847, Loss: 2.2567\n",
      "Epoch 4, Batch 4800/23847, Loss: 2.0202\n",
      "Epoch 4, Batch 4900/23847, Loss: 1.8269\n",
      "Epoch 4, Batch 5000/23847, Loss: 2.0406\n",
      "Epoch 4, Batch 5100/23847, Loss: 2.1445\n",
      "Epoch 4, Batch 5200/23847, Loss: 1.7611\n",
      "Epoch 4, Batch 5300/23847, Loss: 1.9483\n",
      "Epoch 4, Batch 5400/23847, Loss: 1.8866\n",
      "Epoch 4, Batch 5500/23847, Loss: 1.8182\n",
      "Epoch 4, Batch 5600/23847, Loss: 1.8562\n",
      "Epoch 4, Batch 5700/23847, Loss: 2.0219\n",
      "Epoch 4, Batch 5800/23847, Loss: 1.8998\n",
      "Epoch 4, Batch 5900/23847, Loss: 1.9565\n",
      "Epoch 4, Batch 6000/23847, Loss: 2.0710\n",
      "Epoch 4, Batch 6100/23847, Loss: 2.4275\n",
      "Epoch 4, Batch 6200/23847, Loss: 2.1669\n",
      "Epoch 4, Batch 6300/23847, Loss: 1.9430\n",
      "Epoch 4, Batch 6400/23847, Loss: 2.0383\n",
      "Epoch 4, Batch 6500/23847, Loss: 1.8651\n",
      "Epoch 4, Batch 6600/23847, Loss: 2.0216\n",
      "Epoch 4, Batch 6700/23847, Loss: 2.1064\n",
      "Epoch 4, Batch 6800/23847, Loss: 1.8208\n",
      "Epoch 4, Batch 6900/23847, Loss: 1.7994\n",
      "Epoch 4, Batch 7000/23847, Loss: 1.9556\n",
      "Epoch 4, Batch 7100/23847, Loss: 2.1207\n",
      "Epoch 4, Batch 7200/23847, Loss: 1.8726\n",
      "Epoch 4, Batch 7300/23847, Loss: 1.7517\n",
      "Epoch 4, Batch 7400/23847, Loss: 2.0170\n",
      "Epoch 4, Batch 7500/23847, Loss: 2.0641\n",
      "Epoch 4, Batch 7600/23847, Loss: 2.1261\n",
      "Epoch 4, Batch 7700/23847, Loss: 1.9630\n",
      "Epoch 4, Batch 7800/23847, Loss: 2.0994\n",
      "Epoch 4, Batch 7900/23847, Loss: 1.8728\n",
      "Epoch 4, Batch 8000/23847, Loss: 1.9186\n",
      "Epoch 4, Batch 8100/23847, Loss: 2.1623\n",
      "Epoch 4, Batch 8200/23847, Loss: 1.9983\n",
      "Epoch 4, Batch 8300/23847, Loss: 2.2521\n",
      "Epoch 4, Batch 8400/23847, Loss: 2.0431\n",
      "Epoch 4, Batch 8500/23847, Loss: 1.7870\n",
      "Epoch 4, Batch 8600/23847, Loss: 1.9476\n",
      "Epoch 4, Batch 8700/23847, Loss: 2.0644\n",
      "Epoch 4, Batch 8800/23847, Loss: 1.9136\n",
      "Epoch 4, Batch 8900/23847, Loss: 1.7730\n",
      "Epoch 4, Batch 9000/23847, Loss: 2.0169\n",
      "Epoch 4, Batch 9100/23847, Loss: 2.1560\n",
      "Epoch 4, Batch 9200/23847, Loss: 1.7582\n",
      "Epoch 4, Batch 9300/23847, Loss: 2.2050\n",
      "Epoch 4, Batch 9400/23847, Loss: 2.2781\n",
      "Epoch 4, Batch 9500/23847, Loss: 2.0762\n",
      "Epoch 4, Batch 9600/23847, Loss: 1.8570\n",
      "Epoch 4, Batch 9700/23847, Loss: 2.1644\n",
      "Epoch 4, Batch 9800/23847, Loss: 1.9541\n",
      "Epoch 4, Batch 9900/23847, Loss: 1.8765\n",
      "Epoch 4, Batch 10000/23847, Loss: 1.9247\n",
      "Epoch 4, Batch 10100/23847, Loss: 1.9127\n",
      "Epoch 4, Batch 10200/23847, Loss: 2.1091\n",
      "Epoch 4, Batch 10300/23847, Loss: 2.1396\n",
      "Epoch 4, Batch 10400/23847, Loss: 1.9588\n",
      "Epoch 4, Batch 10500/23847, Loss: 1.9012\n",
      "Epoch 4, Batch 10600/23847, Loss: 2.0459\n",
      "Epoch 4, Batch 10700/23847, Loss: 1.9586\n",
      "Epoch 4, Batch 10800/23847, Loss: 1.9616\n",
      "Epoch 4, Batch 10900/23847, Loss: 1.9124\n",
      "Epoch 4, Batch 11000/23847, Loss: 1.9281\n",
      "Epoch 4, Batch 11100/23847, Loss: 1.8346\n",
      "Epoch 4, Batch 11200/23847, Loss: 2.0019\n",
      "Epoch 4, Batch 11300/23847, Loss: 1.9763\n",
      "Epoch 4, Batch 11400/23847, Loss: 2.0912\n",
      "Epoch 4, Batch 11500/23847, Loss: 2.2293\n",
      "Epoch 4, Batch 11600/23847, Loss: 1.8480\n",
      "Epoch 4, Batch 11700/23847, Loss: 1.9723\n",
      "Epoch 4, Batch 11800/23847, Loss: 2.0969\n",
      "Epoch 4, Batch 11900/23847, Loss: 1.8532\n",
      "Epoch 4, Batch 12000/23847, Loss: 1.8459\n",
      "Epoch 4, Batch 12100/23847, Loss: 2.2233\n",
      "Epoch 4, Batch 12200/23847, Loss: 2.0646\n",
      "Epoch 4, Batch 12300/23847, Loss: 2.0096\n",
      "Epoch 4, Batch 12400/23847, Loss: 2.1017\n",
      "Epoch 4, Batch 12500/23847, Loss: 2.0726\n",
      "Epoch 4, Batch 12600/23847, Loss: 2.0308\n",
      "Epoch 4, Batch 12700/23847, Loss: 1.9176\n",
      "Epoch 4, Batch 12800/23847, Loss: 2.1610\n",
      "Epoch 4, Batch 12900/23847, Loss: 2.0154\n",
      "Epoch 4, Batch 13000/23847, Loss: 1.9497\n",
      "Epoch 4, Batch 13100/23847, Loss: 1.7936\n",
      "Epoch 4, Batch 13200/23847, Loss: 1.7968\n",
      "Epoch 4, Batch 13300/23847, Loss: 2.0767\n",
      "Epoch 4, Batch 13400/23847, Loss: 1.8784\n",
      "Epoch 4, Batch 13500/23847, Loss: 1.9573\n",
      "Epoch 4, Batch 13600/23847, Loss: 1.9857\n",
      "Epoch 4, Batch 13700/23847, Loss: 2.0060\n",
      "Epoch 4, Batch 13800/23847, Loss: 1.8162\n",
      "Epoch 4, Batch 13900/23847, Loss: 2.1400\n",
      "Epoch 4, Batch 14000/23847, Loss: 2.3368\n",
      "Epoch 4, Batch 14100/23847, Loss: 2.1788\n",
      "Epoch 4, Batch 14200/23847, Loss: 1.9222\n",
      "Epoch 4, Batch 14300/23847, Loss: 1.9893\n",
      "Epoch 4, Batch 14400/23847, Loss: 1.8654\n",
      "Epoch 4, Batch 14500/23847, Loss: 1.7639\n",
      "Epoch 4, Batch 14600/23847, Loss: 2.0386\n",
      "Epoch 4, Batch 14700/23847, Loss: 1.9732\n",
      "Epoch 4, Batch 14800/23847, Loss: 2.0638\n",
      "Epoch 4, Batch 14900/23847, Loss: 2.0654\n",
      "Epoch 4, Batch 15000/23847, Loss: 1.9402\n",
      "Epoch 4, Batch 15100/23847, Loss: 1.6764\n",
      "Epoch 4, Batch 15200/23847, Loss: 1.8955\n",
      "Epoch 4, Batch 15300/23847, Loss: 2.3323\n",
      "Epoch 4, Batch 15400/23847, Loss: 2.1363\n",
      "Epoch 4, Batch 15500/23847, Loss: 2.0055\n",
      "Epoch 4, Batch 15600/23847, Loss: 2.0288\n",
      "Epoch 4, Batch 15700/23847, Loss: 2.1151\n",
      "Epoch 4, Batch 15800/23847, Loss: 2.0009\n",
      "Epoch 4, Batch 15900/23847, Loss: 1.8351\n",
      "Epoch 4, Batch 16000/23847, Loss: 2.0030\n",
      "Epoch 4, Batch 16100/23847, Loss: 1.9996\n",
      "Epoch 4, Batch 16200/23847, Loss: 1.8325\n",
      "Epoch 4, Batch 16300/23847, Loss: 2.0806\n",
      "Epoch 4, Batch 16400/23847, Loss: 2.0144\n",
      "Epoch 4, Batch 16500/23847, Loss: 2.2732\n",
      "Epoch 4, Batch 16600/23847, Loss: 1.8319\n",
      "Epoch 4, Batch 16700/23847, Loss: 2.0038\n",
      "Epoch 4, Batch 16800/23847, Loss: 2.0231\n",
      "Epoch 4, Batch 16900/23847, Loss: 2.3588\n",
      "Epoch 4, Batch 17000/23847, Loss: 2.1556\n",
      "Epoch 4, Batch 17100/23847, Loss: 2.0337\n",
      "Epoch 4, Batch 17200/23847, Loss: 1.7932\n",
      "Epoch 4, Batch 17300/23847, Loss: 2.0733\n",
      "Epoch 4, Batch 17400/23847, Loss: 1.6885\n",
      "Epoch 4, Batch 17500/23847, Loss: 1.7552\n",
      "Epoch 4, Batch 17600/23847, Loss: 2.0407\n",
      "Epoch 4, Batch 17700/23847, Loss: 1.7868\n",
      "Epoch 4, Batch 17800/23847, Loss: 1.9279\n",
      "Epoch 4, Batch 17900/23847, Loss: 2.1118\n",
      "Epoch 4, Batch 18000/23847, Loss: 1.8940\n",
      "Epoch 4, Batch 18100/23847, Loss: 1.8517\n",
      "Epoch 4, Batch 18200/23847, Loss: 2.1343\n",
      "Epoch 4, Batch 18300/23847, Loss: 2.1010\n",
      "Epoch 4, Batch 18400/23847, Loss: 1.9343\n",
      "Epoch 4, Batch 18500/23847, Loss: 1.8448\n",
      "Epoch 4, Batch 18600/23847, Loss: 2.0612\n",
      "Epoch 4, Batch 18700/23847, Loss: 2.1436\n",
      "Epoch 4, Batch 18800/23847, Loss: 2.0208\n",
      "Epoch 4, Batch 18900/23847, Loss: 1.8296\n",
      "Epoch 4, Batch 19000/23847, Loss: 1.9983\n",
      "Epoch 4, Batch 19100/23847, Loss: 2.0947\n",
      "Epoch 4, Batch 19200/23847, Loss: 1.7865\n",
      "Epoch 4, Batch 19300/23847, Loss: 1.8458\n",
      "Epoch 4, Batch 19400/23847, Loss: 2.1256\n",
      "Epoch 4, Batch 19500/23847, Loss: 1.8300\n",
      "Epoch 4, Batch 19600/23847, Loss: 1.9920\n",
      "Epoch 4, Batch 19700/23847, Loss: 2.0066\n",
      "Epoch 4, Batch 19800/23847, Loss: 1.7524\n",
      "Epoch 4, Batch 19900/23847, Loss: 2.1678\n",
      "Epoch 4, Batch 20000/23847, Loss: 1.9966\n",
      "Epoch 4, Batch 20100/23847, Loss: 1.9557\n",
      "Epoch 4, Batch 20200/23847, Loss: 2.0506\n",
      "Epoch 4, Batch 20300/23847, Loss: 2.0716\n",
      "Epoch 4, Batch 20400/23847, Loss: 2.0453\n",
      "Epoch 4, Batch 20500/23847, Loss: 1.9984\n",
      "Epoch 4, Batch 20600/23847, Loss: 2.0591\n",
      "Epoch 4, Batch 20700/23847, Loss: 2.1748\n",
      "Epoch 4, Batch 20800/23847, Loss: 2.0734\n",
      "Epoch 4, Batch 20900/23847, Loss: 2.3305\n",
      "Epoch 4, Batch 21000/23847, Loss: 1.6754\n",
      "Epoch 4, Batch 21100/23847, Loss: 2.1136\n",
      "Epoch 4, Batch 21200/23847, Loss: 2.1303\n",
      "Epoch 4, Batch 21300/23847, Loss: 1.7297\n",
      "Epoch 4, Batch 21400/23847, Loss: 1.7018\n",
      "Epoch 4, Batch 21500/23847, Loss: 1.9766\n",
      "Epoch 4, Batch 21600/23847, Loss: 1.9079\n",
      "Epoch 4, Batch 21700/23847, Loss: 1.7779\n",
      "Epoch 4, Batch 21800/23847, Loss: 2.0314\n",
      "Epoch 4, Batch 21900/23847, Loss: 2.0976\n",
      "Epoch 4, Batch 22000/23847, Loss: 1.8464\n",
      "Epoch 4, Batch 22100/23847, Loss: 2.0200\n",
      "Epoch 4, Batch 22200/23847, Loss: 1.9247\n",
      "Epoch 4, Batch 22300/23847, Loss: 1.8396\n",
      "Epoch 4, Batch 22400/23847, Loss: 1.9564\n",
      "Epoch 4, Batch 22500/23847, Loss: 2.0046\n",
      "Epoch 4, Batch 22600/23847, Loss: 2.0403\n",
      "Epoch 4, Batch 22700/23847, Loss: 1.7401\n",
      "Epoch 4, Batch 22800/23847, Loss: 1.8310\n",
      "Epoch 4, Batch 22900/23847, Loss: 2.4489\n",
      "Epoch 4, Batch 23000/23847, Loss: 2.1323\n",
      "Epoch 4, Batch 23100/23847, Loss: 1.9877\n",
      "Epoch 4, Batch 23200/23847, Loss: 1.9216\n",
      "Epoch 4, Batch 23300/23847, Loss: 1.9956\n",
      "Epoch 4, Batch 23400/23847, Loss: 1.8457\n",
      "Epoch 4, Batch 23500/23847, Loss: 1.7510\n",
      "Epoch 4, Batch 23600/23847, Loss: 2.0567\n",
      "Epoch 4, Batch 23700/23847, Loss: 2.0946\n",
      "Epoch 4, Batch 23800/23847, Loss: 1.8442\n",
      "Epoch 4, Average Loss: 1.9884, Average Accuracy: 0.5140\n",
      "Model saved to gpt2_model_epoch_4.pth\n",
      "Generated text saved to generated_text_epoch_4.txt\n",
      "Epoch 5, Batch 0/23847, Loss: 1.9184\n",
      "Epoch 5, Batch 100/23847, Loss: 1.7634\n",
      "Epoch 5, Batch 200/23847, Loss: 1.7490\n",
      "Epoch 5, Batch 300/23847, Loss: 1.8686\n",
      "Epoch 5, Batch 400/23847, Loss: 1.9303\n",
      "Epoch 5, Batch 500/23847, Loss: 1.7725\n",
      "Epoch 5, Batch 600/23847, Loss: 1.8116\n",
      "Epoch 5, Batch 700/23847, Loss: 1.9611\n",
      "Epoch 5, Batch 800/23847, Loss: 2.0579\n",
      "Epoch 5, Batch 900/23847, Loss: 1.9905\n",
      "Epoch 5, Batch 1000/23847, Loss: 2.0213\n",
      "Epoch 5, Batch 1100/23847, Loss: 2.0630\n",
      "Epoch 5, Batch 1200/23847, Loss: 1.9894\n",
      "Epoch 5, Batch 1300/23847, Loss: 1.7570\n",
      "Epoch 5, Batch 1400/23847, Loss: 1.9583\n",
      "Epoch 5, Batch 1500/23847, Loss: 2.1636\n",
      "Epoch 5, Batch 1600/23847, Loss: 2.1347\n",
      "Epoch 5, Batch 1700/23847, Loss: 1.8812\n",
      "Epoch 5, Batch 1800/23847, Loss: 1.9333\n",
      "Epoch 5, Batch 1900/23847, Loss: 2.1303\n",
      "Epoch 5, Batch 2000/23847, Loss: 2.1008\n",
      "Epoch 5, Batch 2100/23847, Loss: 1.9852\n",
      "Epoch 5, Batch 2200/23847, Loss: 1.9613\n",
      "Epoch 5, Batch 2300/23847, Loss: 1.8353\n",
      "Epoch 5, Batch 2400/23847, Loss: 1.7114\n",
      "Epoch 5, Batch 2500/23847, Loss: 1.9087\n",
      "Epoch 5, Batch 2600/23847, Loss: 2.0017\n",
      "Epoch 5, Batch 2700/23847, Loss: 1.7256\n",
      "Epoch 5, Batch 2800/23847, Loss: 1.9641\n",
      "Epoch 5, Batch 2900/23847, Loss: 1.7827\n",
      "Epoch 5, Batch 3000/23847, Loss: 1.6934\n",
      "Epoch 5, Batch 3100/23847, Loss: 1.7969\n",
      "Epoch 5, Batch 3200/23847, Loss: 1.7893\n",
      "Epoch 5, Batch 3300/23847, Loss: 1.9062\n",
      "Epoch 5, Batch 3400/23847, Loss: 1.6055\n",
      "Epoch 5, Batch 3500/23847, Loss: 1.9714\n",
      "Epoch 5, Batch 3600/23847, Loss: 2.0105\n",
      "Epoch 5, Batch 3700/23847, Loss: 1.9677\n",
      "Epoch 5, Batch 3800/23847, Loss: 2.0860\n",
      "Epoch 5, Batch 3900/23847, Loss: 1.8571\n",
      "Epoch 5, Batch 4000/23847, Loss: 1.9926\n",
      "Epoch 5, Batch 4100/23847, Loss: 1.7937\n",
      "Epoch 5, Batch 4200/23847, Loss: 2.0580\n",
      "Epoch 5, Batch 4300/23847, Loss: 2.0345\n",
      "Epoch 5, Batch 4400/23847, Loss: 2.0259\n",
      "Epoch 5, Batch 4500/23847, Loss: 2.0139\n",
      "Epoch 5, Batch 4600/23847, Loss: 1.8001\n",
      "Epoch 5, Batch 4700/23847, Loss: 1.7350\n",
      "Epoch 5, Batch 4800/23847, Loss: 1.7706\n",
      "Epoch 5, Batch 4900/23847, Loss: 1.8246\n",
      "Epoch 5, Batch 5000/23847, Loss: 1.7766\n",
      "Epoch 5, Batch 5100/23847, Loss: 2.0030\n",
      "Epoch 5, Batch 5200/23847, Loss: 1.9257\n",
      "Epoch 5, Batch 5300/23847, Loss: 1.8855\n",
      "Epoch 5, Batch 5400/23847, Loss: 1.7497\n",
      "Epoch 5, Batch 5500/23847, Loss: 1.8454\n",
      "Epoch 5, Batch 5600/23847, Loss: 1.8774\n",
      "Epoch 5, Batch 5700/23847, Loss: 1.9763\n",
      "Epoch 5, Batch 5800/23847, Loss: 1.8546\n",
      "Epoch 5, Batch 5900/23847, Loss: 1.8861\n",
      "Epoch 5, Batch 6000/23847, Loss: 2.0719\n",
      "Epoch 5, Batch 6100/23847, Loss: 1.8121\n",
      "Epoch 5, Batch 6200/23847, Loss: 1.8783\n",
      "Epoch 5, Batch 6300/23847, Loss: 1.7973\n",
      "Epoch 5, Batch 6400/23847, Loss: 1.9121\n",
      "Epoch 5, Batch 6500/23847, Loss: 1.8284\n",
      "Epoch 5, Batch 6600/23847, Loss: 1.9348\n",
      "Epoch 5, Batch 6700/23847, Loss: 1.8661\n",
      "Epoch 5, Batch 6800/23847, Loss: 1.8445\n",
      "Epoch 5, Batch 6900/23847, Loss: 1.9378\n",
      "Epoch 5, Batch 7000/23847, Loss: 1.9081\n",
      "Epoch 5, Batch 7100/23847, Loss: 1.9065\n",
      "Epoch 5, Batch 7200/23847, Loss: 1.8290\n",
      "Epoch 5, Batch 7300/23847, Loss: 2.1452\n",
      "Epoch 5, Batch 7400/23847, Loss: 2.0991\n",
      "Epoch 5, Batch 7500/23847, Loss: 2.1518\n",
      "Epoch 5, Batch 7600/23847, Loss: 2.0020\n",
      "Epoch 5, Batch 7700/23847, Loss: 1.7672\n",
      "Epoch 5, Batch 7800/23847, Loss: 1.7697\n",
      "Epoch 5, Batch 7900/23847, Loss: 1.8939\n",
      "Epoch 5, Batch 8000/23847, Loss: 1.8569\n",
      "Epoch 5, Batch 8100/23847, Loss: 2.0437\n",
      "Epoch 5, Batch 8200/23847, Loss: 1.9094\n",
      "Epoch 5, Batch 8300/23847, Loss: 2.0379\n",
      "Epoch 5, Batch 8400/23847, Loss: 1.7792\n",
      "Epoch 5, Batch 8500/23847, Loss: 1.8727\n",
      "Epoch 5, Batch 8600/23847, Loss: 1.7307\n",
      "Epoch 5, Batch 8700/23847, Loss: 2.0794\n",
      "Epoch 5, Batch 8800/23847, Loss: 2.0556\n",
      "Epoch 5, Batch 8900/23847, Loss: 2.0412\n",
      "Epoch 5, Batch 9000/23847, Loss: 1.8583\n",
      "Epoch 5, Batch 9100/23847, Loss: 1.8488\n",
      "Epoch 5, Batch 9200/23847, Loss: 1.9143\n",
      "Epoch 5, Batch 9300/23847, Loss: 2.0768\n",
      "Epoch 5, Batch 9400/23847, Loss: 1.9942\n",
      "Epoch 5, Batch 9500/23847, Loss: 2.0324\n",
      "Epoch 5, Batch 9600/23847, Loss: 1.6180\n",
      "Epoch 5, Batch 9700/23847, Loss: 2.0228\n",
      "Epoch 5, Batch 9800/23847, Loss: 1.8902\n",
      "Epoch 5, Batch 9900/23847, Loss: 1.8207\n",
      "Epoch 5, Batch 10000/23847, Loss: 1.9535\n",
      "Epoch 5, Batch 10100/23847, Loss: 1.9557\n",
      "Epoch 5, Batch 10200/23847, Loss: 1.9943\n",
      "Epoch 5, Batch 10300/23847, Loss: 2.0668\n",
      "Epoch 5, Batch 10400/23847, Loss: 1.9173\n",
      "Epoch 5, Batch 10500/23847, Loss: 1.7707\n",
      "Epoch 5, Batch 10600/23847, Loss: 2.0646\n",
      "Epoch 5, Batch 10700/23847, Loss: 1.8774\n",
      "Epoch 5, Batch 10800/23847, Loss: 1.7644\n",
      "Epoch 5, Batch 10900/23847, Loss: 2.0691\n",
      "Epoch 5, Batch 11000/23847, Loss: 2.0064\n",
      "Epoch 5, Batch 11100/23847, Loss: 1.8423\n",
      "Epoch 5, Batch 11200/23847, Loss: 1.8043\n",
      "Epoch 5, Batch 11300/23847, Loss: 1.8241\n",
      "Epoch 5, Batch 11400/23847, Loss: 1.9750\n",
      "Epoch 5, Batch 11500/23847, Loss: 1.9498\n",
      "Epoch 5, Batch 11600/23847, Loss: 1.7886\n",
      "Epoch 5, Batch 11700/23847, Loss: 1.8029\n",
      "Epoch 5, Batch 11800/23847, Loss: 2.1458\n",
      "Epoch 5, Batch 11900/23847, Loss: 1.5722\n",
      "Epoch 5, Batch 12000/23847, Loss: 1.9148\n",
      "Epoch 5, Batch 12100/23847, Loss: 2.0172\n",
      "Epoch 5, Batch 12200/23847, Loss: 1.6738\n",
      "Epoch 5, Batch 12300/23847, Loss: 1.8060\n",
      "Epoch 5, Batch 12400/23847, Loss: 1.9429\n",
      "Epoch 5, Batch 12500/23847, Loss: 2.0247\n",
      "Epoch 5, Batch 12600/23847, Loss: 2.0600\n",
      "Epoch 5, Batch 12700/23847, Loss: 1.8534\n",
      "Epoch 5, Batch 12800/23847, Loss: 1.7589\n",
      "Epoch 5, Batch 12900/23847, Loss: 1.9681\n",
      "Epoch 5, Batch 13000/23847, Loss: 1.8930\n",
      "Epoch 5, Batch 13100/23847, Loss: 2.1112\n",
      "Epoch 5, Batch 13200/23847, Loss: 2.0672\n",
      "Epoch 5, Batch 13300/23847, Loss: 1.7851\n",
      "Epoch 5, Batch 13400/23847, Loss: 1.9491\n",
      "Epoch 5, Batch 13500/23847, Loss: 1.5397\n",
      "Epoch 5, Batch 13600/23847, Loss: 1.8638\n",
      "Epoch 5, Batch 13700/23847, Loss: 1.8399\n",
      "Epoch 5, Batch 13800/23847, Loss: 2.0383\n",
      "Epoch 5, Batch 13900/23847, Loss: 1.7553\n",
      "Epoch 5, Batch 14000/23847, Loss: 1.8030\n",
      "Epoch 5, Batch 14100/23847, Loss: 1.8887\n",
      "Epoch 5, Batch 14200/23847, Loss: 1.6435\n",
      "Epoch 5, Batch 14300/23847, Loss: 1.8163\n",
      "Epoch 5, Batch 14400/23847, Loss: 1.9511\n",
      "Epoch 5, Batch 14500/23847, Loss: 1.8208\n",
      "Epoch 5, Batch 14600/23847, Loss: 1.8794\n",
      "Epoch 5, Batch 14700/23847, Loss: 1.8096\n",
      "Epoch 5, Batch 14800/23847, Loss: 1.7833\n",
      "Epoch 5, Batch 14900/23847, Loss: 1.7139\n",
      "Epoch 5, Batch 15000/23847, Loss: 2.2128\n",
      "Epoch 5, Batch 15100/23847, Loss: 1.7374\n",
      "Epoch 5, Batch 15200/23847, Loss: 1.8583\n",
      "Epoch 5, Batch 15300/23847, Loss: 1.8932\n",
      "Epoch 5, Batch 15400/23847, Loss: 1.9244\n",
      "Epoch 5, Batch 15500/23847, Loss: 1.9809\n",
      "Epoch 5, Batch 15600/23847, Loss: 2.0273\n",
      "Epoch 5, Batch 15700/23847, Loss: 2.1551\n",
      "Epoch 5, Batch 15800/23847, Loss: 1.7202\n",
      "Epoch 5, Batch 15900/23847, Loss: 1.9016\n",
      "Epoch 5, Batch 16000/23847, Loss: 1.7793\n",
      "Epoch 5, Batch 16100/23847, Loss: 1.9371\n",
      "Epoch 5, Batch 16200/23847, Loss: 2.1532\n",
      "Epoch 5, Batch 16300/23847, Loss: 1.7323\n",
      "Epoch 5, Batch 16400/23847, Loss: 1.8114\n",
      "Epoch 5, Batch 16500/23847, Loss: 2.0692\n",
      "Epoch 5, Batch 16600/23847, Loss: 1.6998\n",
      "Epoch 5, Batch 16700/23847, Loss: 1.7285\n",
      "Epoch 5, Batch 16800/23847, Loss: 2.0604\n",
      "Epoch 5, Batch 16900/23847, Loss: 1.9022\n",
      "Epoch 5, Batch 17000/23847, Loss: 1.8530\n",
      "Epoch 5, Batch 17100/23847, Loss: 1.8565\n",
      "Epoch 5, Batch 17200/23847, Loss: 2.0455\n",
      "Epoch 5, Batch 17300/23847, Loss: 1.7822\n",
      "Epoch 5, Batch 17400/23847, Loss: 1.8781\n",
      "Epoch 5, Batch 17500/23847, Loss: 2.0029\n",
      "Epoch 5, Batch 17600/23847, Loss: 1.9273\n",
      "Epoch 5, Batch 17700/23847, Loss: 1.8710\n",
      "Epoch 5, Batch 17800/23847, Loss: 2.3334\n",
      "Epoch 5, Batch 17900/23847, Loss: 1.9665\n",
      "Epoch 5, Batch 18000/23847, Loss: 2.0149\n",
      "Epoch 5, Batch 18100/23847, Loss: 1.8714\n",
      "Epoch 5, Batch 18200/23847, Loss: 1.7180\n",
      "Epoch 5, Batch 18300/23847, Loss: 1.9061\n",
      "Epoch 5, Batch 18400/23847, Loss: 1.7197\n",
      "Epoch 5, Batch 18500/23847, Loss: 1.9642\n",
      "Epoch 5, Batch 18600/23847, Loss: 1.8590\n",
      "Epoch 5, Batch 18700/23847, Loss: 1.8625\n",
      "Epoch 5, Batch 18800/23847, Loss: 1.7784\n",
      "Epoch 5, Batch 18900/23847, Loss: 1.8526\n",
      "Epoch 5, Batch 19000/23847, Loss: 1.8818\n",
      "Epoch 5, Batch 19100/23847, Loss: 1.8888\n",
      "Epoch 5, Batch 19200/23847, Loss: 1.8080\n",
      "Epoch 5, Batch 19300/23847, Loss: 1.5284\n",
      "Epoch 5, Batch 19400/23847, Loss: 2.1240\n",
      "Epoch 5, Batch 19500/23847, Loss: 1.7003\n",
      "Epoch 5, Batch 19600/23847, Loss: 1.7147\n",
      "Epoch 5, Batch 19700/23847, Loss: 1.6407\n",
      "Epoch 5, Batch 19800/23847, Loss: 1.6418\n",
      "Epoch 5, Batch 19900/23847, Loss: 1.8754\n",
      "Epoch 5, Batch 20000/23847, Loss: 1.9500\n",
      "Epoch 5, Batch 20100/23847, Loss: 1.8252\n",
      "Epoch 5, Batch 20200/23847, Loss: 1.9486\n",
      "Epoch 5, Batch 20300/23847, Loss: 1.9123\n",
      "Epoch 5, Batch 20400/23847, Loss: 2.1043\n",
      "Epoch 5, Batch 20500/23847, Loss: 1.7542\n",
      "Epoch 5, Batch 20600/23847, Loss: 1.9026\n",
      "Epoch 5, Batch 20700/23847, Loss: 1.8924\n",
      "Epoch 5, Batch 20800/23847, Loss: 1.8826\n",
      "Epoch 5, Batch 20900/23847, Loss: 1.8012\n",
      "Epoch 5, Batch 21000/23847, Loss: 1.9054\n",
      "Epoch 5, Batch 21100/23847, Loss: 1.8556\n",
      "Epoch 5, Batch 21200/23847, Loss: 2.0712\n",
      "Epoch 5, Batch 21300/23847, Loss: 1.9197\n",
      "Epoch 5, Batch 21400/23847, Loss: 1.9069\n",
      "Epoch 5, Batch 21500/23847, Loss: 1.8943\n",
      "Epoch 5, Batch 21600/23847, Loss: 1.8736\n",
      "Epoch 5, Batch 21700/23847, Loss: 1.7871\n",
      "Epoch 5, Batch 21800/23847, Loss: 1.7277\n",
      "Epoch 5, Batch 21900/23847, Loss: 1.9803\n",
      "Epoch 5, Batch 22000/23847, Loss: 1.8278\n",
      "Epoch 5, Batch 22100/23847, Loss: 2.2637\n",
      "Epoch 5, Batch 22200/23847, Loss: 1.9918\n",
      "Epoch 5, Batch 22300/23847, Loss: 1.8692\n",
      "Epoch 5, Batch 22400/23847, Loss: 2.0486\n",
      "Epoch 5, Batch 22500/23847, Loss: 1.9053\n",
      "Epoch 5, Batch 22600/23847, Loss: 1.7952\n",
      "Epoch 5, Batch 22700/23847, Loss: 1.9210\n",
      "Epoch 5, Batch 22800/23847, Loss: 1.9478\n",
      "Epoch 5, Batch 22900/23847, Loss: 1.8617\n",
      "Epoch 5, Batch 23000/23847, Loss: 1.7692\n",
      "Epoch 5, Batch 23100/23847, Loss: 2.0515\n",
      "Epoch 5, Batch 23200/23847, Loss: 1.9234\n",
      "Epoch 5, Batch 23300/23847, Loss: 2.0570\n",
      "Epoch 5, Batch 23400/23847, Loss: 2.1793\n",
      "Epoch 5, Batch 23500/23847, Loss: 1.7972\n",
      "Epoch 5, Batch 23600/23847, Loss: 1.9256\n",
      "Epoch 5, Batch 23700/23847, Loss: 1.7169\n",
      "Epoch 5, Batch 23800/23847, Loss: 1.9092\n",
      "Epoch 5, Average Loss: 1.9157, Average Accuracy: 0.5263\n",
      "Model saved to gpt2_model_epoch_5.pth\n",
      "Generated text saved to generated_text_epoch_5.txt\n",
      "Final model saved to gpt2_model.pth\n",
      "Training metrics plot saved to 'training_metrics.png'\n",
      "Model loaded from gpt2_model.pth\n",
      "Test Perplexity: 7.21\n",
      "Generated Text:\n",
      "Once upon a time, in a small village, there was a little girl named Lily. She loved to play with her toys and her friends. One day, Lily's mom asked her to clean up her toys. Lily didn't want to clean up, but she knew it was important to listen\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Total training samples: {len(train_dataset)}\")\n",
    "    print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "    # Option 1: Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, epochs=5, save_path=\"gpt2_model.pth\", accum_steps=2)\n",
    "\n",
    "    # Option 2: Load pre-trained model and test\n",
    "    model = load_model(model, load_path=\"gpt2_model.pth\")\n",
    "\n",
    "    # Evaluate perplexity\n",
    "    perplexity = compute_perplexity(model, test_loader)\n",
    "    print(f\"Test Perplexity: {perplexity:.2f}\")\n",
    "\n",
    "    # Generate sample text\n",
    "    prompt = \"Once upon a time, in a small village\"\n",
    "    generated_text = generate_text(model, prompt, max_length=50, method=\"greedy\")\n",
    "    print(f\"Generated Text:\\n{generated_text}\")\n",
    "\n",
    "    # Save generated text for report\n",
    "    with open(\"generated_text.txt\", \"w\") as f:\n",
    "        f.write(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faed6cc",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f316f67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model loaded from D:\\me\\College\\3rd year 2nd term\\Pattern\\final project\\gpt2_model.pth\n",
      "\n",
      "Prompt: I have a cat\n",
      "Generated Text: I have a cat. The cat named Kitty was very happy cat. Kitty loved to play with her tail and run around the house.\n",
      "One day, Kitty saw a big box in the box. Kitty wanted to play with the box. She ran to open it.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "# 2. Multi-Head Self-Attention\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.scale = math.sqrt(self.d_k)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        Q = self.W_q(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.W_o(context)\n",
    "        return output\n",
    "\n",
    "# 3. Feed-Forward Neural Network\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))\n",
    "\n",
    "# 4. Transformer Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_output = self.self_attn(x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "# 5. GPT-2 Model\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=768, num_layers=2, num_heads=12, d_ff=3072, max_len=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def generate(self, input_ids, max_length=50, method=\"greedy\"):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                mask = torch.tril(torch.ones(input_ids.size(1), input_ids.size(1), device=device)).unsqueeze(0).unsqueeze(0)\n",
    "                logits = self(input_ids, mask)[:, -1, :]\n",
    "                if method == \"greedy\":\n",
    "                    next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "                else:\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    next_token = torch.multinomial(probs, num_samples=1)\n",
    "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "                if next_token.item() == tokenizer.eos_token_id:\n",
    "                    break\n",
    "        return input_ids\n",
    "\n",
    "# 6. Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 7. Load Model\n",
    "def load_model(model, load_path=\"gpt2_model.pth\"):\n",
    "    model.load_state_dict(torch.load(load_path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {load_path}\")\n",
    "    return model\n",
    "\n",
    "# 8. Generate Text\n",
    "def generate_text(model, prompt, max_length=50, method=\"greedy\"):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(input_ids, max_length, method)\n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    model = GPT2(vocab_size=vocab_size, d_model=768, num_layers=2, num_heads=12, d_ff=3072, max_len=256).to(device)\n",
    "\n",
    "    # Load saved model \n",
    "    load_path = r\"D:\\me\\College\\3rd year 2nd term\\Pattern\\final project\\gpt2_model.pth\" # Put the model path here.\n",
    "    model = load_model(model, load_path)\n",
    "\n",
    "    # Test\n",
    "    prompts = [\n",
    "        \"I have a cat\",\n",
    "    ]\n",
    "\n",
    "    for prompt in prompts:\n",
    "        generated_text = generate_text(model, prompt, max_length=50, method=\"greedy\")\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated Text: {generated_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
